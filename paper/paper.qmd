---
title: "Beef Pricing Dynamics in the Canadian Grocery Market: A Comparative Analysis of Walmart and T&T"
subtitle: "Evidence of Cultural and Strategic Influences on Beef Pricing"
author: 
  - Ziheng Zhong
thanks: "Code and data supporting this analysis is available at: [Link to repository](https://github.com/iJustinn/Canadian_Grocery_Analysis.git)."
date: today
date-format: long
abstract: "This study examines beef pricing in the Canadian grocery market, focusing on Walmart and T&T as representative vendors. Using Bayesian linear regression, it analyzes how historical prices, vendor-specific strategies, and seasonal effects impact current beef prices. The findings indicate that historical pricing strongly predicts current prices, while vendor approaches differ significantly, with Walmart maintaining consistent pricing and T&T showing greater variability. This research highlights how cultural preferences and retail strategies influence food pricing, enhancing our understanding of market behavior and supporting both consumer choices and policy development."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
# load library
package_list <- c("tidyverse", "kableExtra", "ggplot2", "dplyr", "here", "knitr", "rstanarm", "modelsummary", "readr", "lme4", "tinytex", "reshape2", "arrow")

install_and_load <- function(package_list) {
  for (package in package_list) {
    if (!require(package, character.only = TRUE)) {
      install.packages(package)
      library(package, character.only = TRUE)
    }
  }
}

install_and_load(package_list)

# load data
ppu_data <- read_parquet(here("data", "02-analysis_data", "ppu_data.parquet"))
beef_data <- read_parquet(here("data", "02-analysis_data", "beef_data.parquet"))
merge_data  <- read_parquet(here("data", "02-analysis_data", "merged_data.parquet"))

# load model
beef_model <- readRDS (file = here:: here ("models/beef_model.rds"))
```



# Introduction

The pricing of grocery items, particularly beef, plays an important role in understanding consumer behavior and market trends within the Canadian retail sector. As a staple in many households, beef pricing is shaped by various factors, including vendor strategies [@citePricingStrategies], historical trends, and seasonal variations [@citeSeasonal]. This study focuses on examining how major retailers adjust beef prices over time and how these adjustments reflect broader economic and cultural patterns. With growing concerns around food affordability and access, analyzing beef pricing dynamics is essential for both consumers and stakeholders involved in food distribution and policy-making.

This paper centers on two significant vendors, Walmart and T&T, to investigate how beef pricing differs across retail environments. Walmart, a global retailer, exemplifies standardized pricing strategies [@citeWalmart], while T&T, catering primarily to Asian communities, represents a more targeted market segment [@citeTandT]. By analyzing data from these vendors, the study addresses an often-overlooked aspect of how cultural preferences and retail strategies influence pricing. Previous research has focused on general trends in food pricing but has not fully considered the distinctions between mainstream retail chains and culturally specific stores. This analysis provides a detailed comparison of beef pricing patterns in these two diverse settings.

The estimand of this study is the current price of beef, determined by factors such as vendor type, historical pricing, etc. By estimating how these variables impact the current pricing, the paper aims to provide a comprehensive understanding of the pricing mechanisms that affect retail beef prices in Canada.

Using a Bayesian linear regression model, this study analyzes the effects of historical pricing, vendor strategies, and seasonal factors on current beef prices. The findings show that past prices are strong predictors of current pricing, indicating a high level of consistency. Walmart’s pricing strategy emphasizes stability, while T&T exhibits more variability, likely catering to specific consumer needs. These results enhance our understanding of pricing practices across different retail contexts and shed light on factors influencing affordability and purchasing patterns in the market.

The paper is structured as follows: @sec-data describes the data collection and cleaning methods, as well as the outcome and predictor variables used in the analysis. @sec-model introduces the forecasting models and explains their selection for predicting beef prices. @sec-result presents the key findings, including vendor-specific pricing effects and seasonal trends. Lastly, @sec-discussion interprets these results, comparing vendor strategies, identifying significant patterns, and discussing the study's limitations.

# Data {#sec-data}

This project is motivated and guided by Rohan Alexander and his book [@citeTbook]. Data used in this paper was cleaned, analyzed and modeled with the programming language R [@citeR]. Also with support of additional packages in R: `readr` [@citeReadr], `ggplot2` [@citeGgplot2], `tidyverse` [@citeTidyverse], `dplyr` [@citeDplyr], `here` [@citeHere], `knitr` [@citeKnitr], `kableExtra` [@citeKableExtra], `rstanarm` [@citeRstanarm], `modelsummary` [@citeModelsummary], `lme4` [@citeLme4], `tinytex` [@citeTinytex], `reshape2` [@citeReshape2], `arrow` [@citeArrow].

Details about data cleaning and variable selection can be found in [Appendix -@sec-data_details].

## Source

The dataset for this research was obtained from Hammer, a publicly accessible repository offering pricing information from a variety of retail chains. It includes details on product attributes such as name, vendor, current and old prices, available units, and the month associated with certain prices. The dataset focuses on consumer pricing trends across different vendors, enabling an analysis of how factors like vendor type, historical pricing, and seasonal changes affect current prices. This provides a basis for examining retail market behaviors and assessing vendor pricing strategies.

The dataset contains both categorical and numerical variables. Important variables include ‘vendor,’ which identifies the retailer (e.g., Walmart, Galleria), and ‘product_name,’ which specifies the item being analyzed. Variables like ‘current_price’ and ‘old_price’ help track pricing changes, while temporal variables such as ‘month’ allow for the identification of seasonal pricing patterns. Summary statistics and visualizations have been generated to illustrate the distributions and relationships of these variables. These graphs include frequency distributions for vendors, trends in price changes, and comparisons between old and current prices. Relationships such as those between ‘vendor’ and ‘current_price’ are highlighted to present a detailed view of the dataset.

Alternative datasets, such as proprietary retail databases or other consumer purchasing records, were considered for this analysis. However, these were not selected due to limitations in accessibility, licensing restrictions, or insufficient detail in product-level attributes. The Hammer dataset was chosen because it provides detailed pricing data necessary for analyzing product-level trends across various vendors. It also enabled the creation of derived variables, such as ‘price_per_unit,’ which facilitated more meaningful comparisons between products. Data cleaning efforts included addressing missing values in the ‘old_price’ variable by replacing them with the ‘current_price,’ ensuring consistency and completeness in the analysis.

## Measurement

The data for Project Hammer, focused on historical grocery prices, does not explicitly describe its collection methods. However, automated web scraping is a feasible approach for gathering this information. This method extracts structured information from retailer websites, capturing details such as product names, prices, brands, and unit measurements. The process involves developing scripts or utilizing tools that navigate websites, identify relevant HTML elements, and store the data in structured formats like CSV files or databases. To maintain accuracy and consistency, scraping schedules can be automated at regular intervals, such as weekly or monthly, to monitor price changes over time. Moreover, including user-agent strings and introducing delays in the scraping process helps simulate human browsing behavior and reduce the risk of triggering website anti-scraping mechanisms.

This research translates real-world phenomena into structured data entries within the dataset to analyze pricing behavior effectively. Variables such as ‘vendor,’ ‘current_price,’ and ‘month’ capture consumer purchasing patterns and their relationships with retail environments. The ‘vendor’ variable identifies the retailer, allowing an analysis of how retail settings influence pricing strategies. The ‘current_price’ and ‘old_price’ variables document pricing trends, enabling the measurement of changes in consumer costs over time and their connections to economic activity.

The ‘month’ variable introduces a temporal aspect, capturing the influence of seasonal patterns on pricing. Derived variables, such as ‘price_per_unit,’ standardize product comparisons by accounting for differences in package sizes or quantities. This transformation of consumer behavior and retail dynamics into structured data ensures that the analysis remains tied to real-world market activities, enhancing the understanding of pricing trends and behaviors across various retail contexts.

Additional details about the dataset are provided in the datasheet, which can be accessed through the repository associated with this paper.

## Outcome variables

The outcome variable for this study, current_price, is the central focus for analyzing product pricing patterns in the Canadian grocery market. It represents the price of beef at the time of data collection, providing a direct measure of how prices vary across different retail settings. By examining current_price, the study captures both short-term price changes and longer-term strategies used by vendors.

This section outlines the characteristics of the current_price variable, including its distribution and observed patterns, supported by summary statistics and visualizations. Key statistics, such as the mean, median, minimum, and maximum values, describe the central tendency and range of beef prices across vendors. Measures of variability, such as the standard deviation, illustrate the extent of price dispersion, showing how consistently prices are set across products and time. This descriptive analysis establishes a basis for identifying significant patterns in beef pricing.

### Current Price

This variable represents the price of the product at the time of data collection and serves as the foundation for analyzing how various factors influence pricing. By modeling current_price, the study examines the impact of historical pricing, vendor type, and seasonal patterns on current market prices. Understanding this variable is essential for identifying pricing strategies used by vendors and their effects on consumer expenses.

To present an overview of the outcome variable, a table is provided (@tbl-current_price). This table includes key statistics such as the minimum, maximum, mean, median, and standard deviation of the current_price variable. These measures summarize the distribution and variability of product prices, helping to characterize overall pricing patterns in the dataset.

```{r}
#| label: tbl-current_price
#| tbl-cap: "Summary statistics for the outcome variable (current_price)"
#| echo: false
#| warning: false
#| message: false

outcome_summary <- beef_data %>%
  summarise(
    Statistic = c("Min", "Max", "Mean", "Median", "Standard Deviation"),
    Value = c(
      round(min(current_price, na.rm = TRUE), 3),
      round(max(current_price, na.rm = TRUE), 3),
      round(mean(current_price, na.rm = TRUE), 3),
      round(median(current_price, na.rm = TRUE), 3),
      round(sd(current_price, na.rm = TRUE), 3)
    )
  )

outcome_summary %>%
  kable(
    col.names = c("Statistic", "Value"),
    booktabs = TRUE
  )
```

@tbl-current_price highlighting key measures of central tendency and variability. The data ranges from a minimum value of 0.77 to a maximum of 23.98, illustrating a broad spread. The mean value is 9.11, indicating that most beef prices are concentrated around this range. The median is 8.58, suggesting that half of the observations fall below this value. The proximity of the mean and median implies a relatively symmetric distribution. The standard deviation of 4.33 reflects moderate variability, indicating that most values are distributed within approximately 4.33 units of the mean, providing a clearer understanding of the data's spread.

In addition to the summary table, @fig-current_price visualizes the distribution of current_price, showing common price ranges and the overall spread. This graph helps identify any skewness or clustering in the data, which could indicate specific pricing patterns. Combined, the table and histogram provide a detailed overview of the outcome variable, illustrating how product prices differ among vendors and change over time.

```{r}
#| label: fig-current_price
#| fig-cap: "Boxplot of the distribution of current prices"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 5

ggplot(beef_data, aes(y = current_price)) +
  geom_boxplot(fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  labs(y = "Current Price (in $)") +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

```

The @fig-current_price provides an overview of the distribution of current_price for the products in the dataset. This visualization highlights key features such as the median price, interquartile range (IQR), and any potential outliers in the pricing data.

The median, represented by the horizontal line within the box, indicates the central tendency of product prices, showing where most values are centered. The box itself represents the IQR, which captures the range within which the middle 50% of prices fall, offering a view of price concentration. The whiskers extending from the box depict the range of prices outside the IQR, excluding extreme values. In this case, no significant outliers were detected, suggesting that product prices are generally within a consistent range.

The relatively flat boxplot, combined with a narrow IQR, indicates limited variability in current_price. The small difference between the lower and upper bounds of the box suggests that product pricing is consistent, with most prices clustering around the median. This consistency could reflect standardized pricing strategies among vendors or a lack of variation in the types of products sold. Overall, the boxplot effectively summarizes the distribution of current_price and provides a clear view of pricing patterns across vendors.

## Predictor variables

The predictor variables in this study—month, old_price, and vendor—each contribute to explaining variations in current_price and provide a structured view of the factors influencing beef pricing across retail settings. These variables reflect temporal trends, the influence of historical pricing, and differences in vendor strategies, collectively aiding in the understanding of product pricing in the Canadian grocery market.

The month variable represents the temporal aspect of pricing, enabling the analysis of seasonal patterns in beef prices. Treating month as a categorical variable allows for the identification of months with higher or lower prices, potentially tied to changes in demand due to holidays, promotions, or seasonal supply fluctuations. For instance, months associated with holidays like Thanksgiving or cultural festivals may show increased demand, which could lead to price adjustments. This temporal perspective helps to assess whether vendors apply seasonal pricing strategies that influence current_price over time.

### Month

The month variable serves as a predictor to account for seasonal effects on pricing. Including month allows the analysis to identify whether certain times of the year are associated with price fluctuations. Factors such as holidays, promotional events, or changes in seasonal demand may contribute to these variations. @tbl-month_summary presents a breakdown of the observations for each month, showing the frequency of data collection across the year. This summary helps identify any months with disproportionately high or low representation, which could impact the interpretation of seasonal pricing patterns.

```{r}
#| label: tbl-month_summary
#| tbl-cap: "Summary statistics for the predictor variable (month)"
#| echo: false
#| warning: false
#| message: false

month_summary <- beef_data %>%
  group_by(month) %>%
  summarise(
    Count = n()
  )

month_summary %>%
  kable(
    col.names = c("Month", "Count"),
    booktabs = TRUE
  )

```

The @tbl-month_summary presents the number of observations recorded for each month, spanning June to November. The highest count is in August (624), while the lowest is in November (342). This variation may reflect increased market activity or data collection efforts during the summer, possibly due to higher consumer demand during barbecue season. Conversely, the decline in November could be linked to reduced data collection or changes in consumer purchasing patterns. Since data collection began in early 2024, the dataset does not represent the entire year, limiting the ability to evaluate pricing trends across all seasons. These monthly differences highlight the importance of accounting for seasonal factors when analyzing pricing patterns.

### Old Price

old_price is a key predictor variable that represents a product's historical price. This variable is used to examine how past pricing influences current pricing strategies, indicating whether products have experienced discounts or price increases. @tbl-old_price_summary summarizes the key statistics for old_price, including its minimum, maximum, mean, median, and standard deviation. Analyzing the distribution of old_price allows us to evaluate whether historical prices significantly differ from current prices and whether adjustments, such as discounts, are applied consistently across products. The relationship between old_price and current_price is further illustrated in Chart 4, providing a visual representation of how historical pricing affects current price decisions.

```{r}
#| label: tbl-old_price_summary
#| tbl-cap: "Summary statistics for the predictor variable (old_price)"
#| echo: false
#| warning: false
#| message: false

old_price_summary <- beef_data %>%
  summarise(
    Statistic = c("Min", "Max", "Mean", "Median", "Standard Deviation"),
    Value = c(
      round(min(current_price, na.rm = TRUE), 3),
      round(max(current_price, na.rm = TRUE), 3),
      round(mean(current_price, na.rm = TRUE), 3),
      round(median(current_price, na.rm = TRUE), 3),
      round(sd(current_price, na.rm = TRUE), 3)
  )
)

old_price_summary %>%
  kable(
    col.names = c("Statistic", "Value"),
    booktabs = TRUE
  )

```

The @tbl-old_price_summary summarizes the statistics for the predictor variable old_price, representing the historical price of beef. The minimum value is \$1.87, and the maximum value is \$25.99, reflecting a wide range of historical prices for beef products. The mean value of \$11.48 indicates that, on average, beef products were priced near this level in the past. The median of \$10.97 shows that half of the products had historical prices below this value, suggesting a slightly skewed distribution. The standard deviation of \$5.32 reflects moderate variability, indicating that while many products were priced close to the average, some were significantly higher or lower. These statistics help describe the variation and central tendency in historical beef pricing.

### Vendor

The vendor variable is a categorical predictor that captures differences in pricing behavior across retail chains. It enables the analysis of how pricing strategies differ among vendors. @tbl-vendor_summary lists the number of observations for each vendor, helping to evaluate the representation of each retail chain in the dataset and determine whether certain vendors have a larger impact on the overall analysis.

```{r}
#| label: tbl-vendor_summary
#| tbl-cap: "Count of observations for each vendor"
#| echo: false
#| warning: false
#| message: false

vendor_summary <- beef_data %>%
  group_by(vendor) %>%
  summarise(
    Count = n()
  )

vendor_summary %>%
  kable(
    col.names = c("Vendor", "Count"),
    booktabs = TRUE
  )

```

The @tbl-vendor_summary presents the number of observations for each vendor, with Walmart accounting for 1,696 and T&T for 1,330. While there is a difference in the number of observations, the counts are close enough to allow for a meaningful comparison between the two vendors. This indicates that while Walmart may offer a slightly wider range or maintain more consistent availability of beef products, T&T’s dataset is still robust enough to analyze pricing patterns effectively. This balance ensures the analysis reflects variations between a mainstream retailer and a culturally focused store without being significantly affected by unequal sample sizes.

# Model {#sec-model}

Background details and diagnostics are included in [Appendix -@sec-model-details].

## Overview

To model the current price of beef, $y_i$, at time $i$, we apply a Bayesian linear regression model using the `stan_glm` function from the R package `rstanarm`. The response variable, $y_i$, represents the current price of beef in dollars. The predictors include $x_1$, $x_2$, and $x_3$, corresponding to the month, old price, and vendor, respectively. Each component of the model is defined and explained in the following sections.

## Set-up

Define $y_i$ as the current price of beef at time $i$, expressed in dollars. The predictors are represented as follows: $x_1$ is the month (a categorical variable), $x_2$ is the old price, and $x_3$ is the vendor (a categorical variable).

\begin{align}
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i}
\end{align}

In this model:
- $\alpha$ denotes the intercept term, representing the baseline price of beef when all predictors are at their reference levels.  
- $\beta_1$ represents the effect of the month on the current price, capturing seasonal patterns that may influence beef prices. The month is treated as a categorical variable, recognizing that demand and supply conditions can vary by month due to factors such as holidays, weather, or promotional periods.  
- $\beta_2$ reflects the effect of the old price on the current price, accounting for the influence of historical pricing. This term helps identify whether past prices have a consistent impact on current pricing decisions.  
- $\beta_3$ captures the effect of the vendor, also treated as a categorical variable. Different vendors may apply unique pricing strategies, and including this variable allows us to model variations specific to each vendor.

We assume normal priors for the model coefficients and intercept, with mean 0 and standard deviation 2.5:

\begin{align}
\alpha &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5)
\end{align}

These priors are designed to be weakly informative, offering guidance while allowing the data to determine the outcomes. A standard deviation of 2.5 reflects the expectation that most effects are likely to fall within a reasonable range, ensuring the priors are flexible without imposing overly restrictive assumptions.

For the residual standard deviation, $\sigma$, we assume an Exponential(1) prior:

\begin{align}
\sigma &\sim \text{Exponential}(1)
\end{align}

This prior reflects our belief that the standard deviation should be positive and allows flexibility, while preferring smaller values over larger ones, consistent with the expectation of modest variability around the mean prediction.

We run the model in R [@citeR] using the `rstanarm` package of @citeRstanarm. We use the default priors from `rstanarm`.

## Justification

The selected predictors strike a balance between relevance and simplicity for this scenario. Including `month` and `vendor` as categorical variables accounts for the influence of seasonal changes and vendor-specific pricing strategies on the current price of beef. The use of `old_price` reflects the concept of price inertia, where past prices are likely to affect current pricing patterns.

The model avoids being overly simplistic or unnecessarily complex by incorporating key predictors without introducing excessive variables that could risk overfitting. Treating `month` and `vendor` as categorical variables ensures the model captures relevant distinctions without arbitrary groupings, maintaining both clarity and parsimony.

The model is implemented using `stan_glm` from the `rstanarm` package, which provides an accessible interface to Stan for Bayesian modeling. Stan's efficient sampling algorithms ensure reliable convergence and accurate estimation of posterior distributions, making it a robust choice for this analysis.

### Assumptions and Limitations
- **Linearity**: The model assumes a linear relationship between the predictors (month, old_price, vendor) and the response variable (current_price). This assumption simplifies the analysis and enhances interpretability, but it may limit the model's ability to capture more complex relationships. For example, interactions or threshold effects between predictors and the response variable would not be reflected in a purely linear framework. If these nonlinear relationships exist but are not modeled, the resulting estimates and predictions may be less accurate, potentially leading to incorrect conclusions about factors affecting beef pricing.

- **Normality of Residuals**: The residuals are assumed to follow a normal distribution, a requirement for making valid statistical inferences about model parameters. If this assumption is violated—such as when residuals are skewed or have heavy tails—it could result in biased estimates, unreliable confidence intervals, and less dependable predictions. Non-normal residuals might suggest missing variables in the model or that a different modeling approach, such as a generalized linear model, might better fit the data.

- **Priors**: The Bayesian framework employs weakly informative priors to allow the data to primarily determine parameter estimates. While this provides flexibility, it also means that stronger prior knowledge of pricing patterns could have been used to improve precision. Using more specific priors, informed by domain knowledge, might enhance the model's performance by producing more stable estimates. However, weakly informative priors can make the model more sensitive to data quality and outliers, as they do not strongly influence the parameter estimates. In cases where the data are limited or noisy, stronger priors could help stabilize the model's outputs.

### Validation and Diagnostics
- **Posterior Predictive Checks**: Posterior predictive checks were conducted to evaluate how well the model represents the variation in the data. These checks compare simulated data generated from the posterior distribution to the observed data to identify any discrepancies. Assessing the alignment between these distributions helps determine whether the model captures the underlying patterns in the data. A close match indicates that the model is appropriately capturing the structure of the data, while notable differences may suggest issues such as omitted variables or an incorrect model specification. These checks are a key step in validating the model's ability to generalize beyond the observed dataset.

- **Convergence**: Model convergence was assessed using trace plots and the R-hat statistic, with all R-hat values near 1, confirming successful convergence. Trace plots illustrate how effectively the Markov Chain Monte Carlo (MCMC) sampling algorithm explores the parameter space. Well-mixed chains with stable trajectories suggest the model has reached a stationary distribution. The R-hat statistic, also known as the Gelman-Rubin diagnostic, compares between-chain and within-chain variance, with values close to 1 indicating that all chains have converged to the same target distribution. Together, these diagnostics ensure the reliability of the parameter estimates and confirm that sampling issues did not influence the results.

- **Alternative Models**: Simpler linear models excluding vendor or seasonal variables were also tested. These models showed notably lower predictive performance, highlighting the importance of including both vendor and seasonal factors for accurate modeling. Excluding these variables reduced the model's fit, as indicated by metrics like R-squared and predictive accuracy. This comparison reinforces the necessity of accounting for vendor-specific strategies and seasonal variations to effectively model beef pricing. The evaluation of alternative models confirmed that the selected predictors provide a better representation of the factors influencing price changes in the dataset.

In conclusion, the chosen model effectively captures how various factors influence the current price of beef. The Bayesian framework incorporates uncertainty and prior knowledge, while the selection of priors and predictors ensures the model aligns well with the available data and research objectives.

# Results {#sec-result}

## Charting

```{r}
#| label: fig-current_price_distribution
#| fig-cap: "Distribution of Current Prices"
#| echo: false
#| warning: false
#| message: false

ggplot(beef_data, aes(x = current_price)) +
  geom_histogram(binwidth = 1, fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  geom_density(aes(y = ..count..), color = "red", size = 0.8) +
  labs(x = "Current Price (in $)", y = "Frequency") +
  theme_minimal()

```

@fig-current_price_distribution illustrates the distribution of current beef prices in the dataset, depicting how prices are spread across different levels. The horizontal axis represents beef prices in dollars, ranging from 0 to approximately 25, while the vertical axis shows the frequency, or the number of observations, within each price range. The grey bars represent the histogram, visualizing the frequency distribution of beef prices.

The histogram shows that the most common price range is between \$4 and \$8, with noticeable peaks around \$5 and \$8. This indicates that a significant portion of beef products falls within this range, suggesting a central pricing cluster in the market. Smaller peaks around \$13 and \$15 point to secondary groupings where beef prices are also relatively frequent. Beyond \$15, the frequency declines sharply, indicating that higher-priced beef products are less common and that most items are concentrated within a lower price range.

The overlaid red line represents a smoothed density curve, highlighting the overall trend in the distribution. The curve closely aligns with the histogram, showing a skewed pattern with a higher concentration of prices in the lower range and a gradual decrease as prices rise. This distribution suggests that consumers may prefer lower-priced beef products or that pricing aligns with affordability constraints. The multiple peaks in the curve indicate distinct pricing tiers, potentially reflecting differences in product quality, cut types, or retailer-specific pricing strategies.

```{r}
#| label: fig-price_difference_by_vendor
#| fig-cap: "Price Difference by Vendor"
#| echo: false
#| warning: false
#| message: false

beef_data <- beef_data %>%
  mutate(price_difference = old_price - current_price)

ggplot(beef_data, aes(x = vendor, y = price_difference)) +
  geom_boxplot(fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  labs(x = "Vendor", y = "Price Difference (in $)") +
  theme_minimal()

```

@fig-price_difference_by_vendor shows the distribution of price differences for beef products sold by T&T and Walmart, highlighting variations in pricing between these retailers. The y-axis represents the price difference in dollars, while the x-axis lists the two vendors. The boxplots display the range, median, and variability of price differences for each retailer.

For T&T, the boxplot indicates a broader range of price differences, with the interquartile range (IQR) spanning approximately \$1.5 to \$4. The median price difference is about \$2.5, suggesting that many products cluster around this value. T&T also shows greater variability, with outliers extending beyond \$7.5 and \$10. These outliers suggest that certain products have significantly larger price differences, possibly reflecting diverse pricing strategies or variations in product offerings.

In comparison, Walmart's boxplot shows a narrower distribution of price differences. The IQR ranges from roughly \$1 to \$2.5, with a median of around \$1.5. This tighter range indicates that Walmart’s beef pricing differences are more consistent, reflecting a standardized pricing strategy. While there are a few outliers above \$4, these deviations are less pronounced than those seen for T&T.

The boxplots emphasize a clear difference in pricing approaches: T&T exhibits more variability and larger outliers, potentially due to a broader product assortment or targeted market strategies. Walmart, on the other hand, maintains more uniform pricing, offering greater predictability for consumers. These patterns reflect how each retailer positions its beef products in the market.

```{r}
#| label: fig-average_price_over_time
#| fig-cap: "Average Daily Current Price Over Time"
#| echo: false
#| warning: false
#| message: false

beef_data <- beef_data %>%
  mutate(date = as.Date(paste(year, month, day, sep = "-"), format = "%Y-%m-%d"))

avg_price_per_date <- beef_data %>%
  group_by(date) %>%
  summarise(avg_current_price = mean(current_price, na.rm = TRUE))

ggplot(avg_price_per_date, aes(x = date, y = avg_current_price)) +
  geom_point(color = "grey", size = 1.5, alpha = 0.7) +
  geom_smooth(method = "loess", color = "red", fill = "darkgrey", alpha = 0.3, se = TRUE) +
  labs(x = "Date", y = "Average Current Price (in $)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

@fig-average_price_over_time displays the trend in average beef prices from July to November, highlighting fluctuations in the market during this period. The y-axis represents the average current price in dollars, while the x-axis shows the progression of dates.

The chart shows a general downward trend in average prices starting in early July, when prices were around \$11, and decreasing to approximately \$7 by the end of the month. This decline could reflect changes in market dynamics, such as seasonal shifts in demand or adjustments in supply. In August, prices display moderate fluctuations, with occasional spikes above \$9, possibly due to short-term disruptions or promotional pricing events.

September and October show a more consistent decline, with average prices dropping below \$6 at times. This extended period of lower prices may point to factors like an oversupply or reduced consumer demand. Toward the end of October, prices begin to recover, showing a gradual upward trend into early November and stabilizing between \$8 and \$9. The shaded region around the line, representing confidence intervals, widens at the edges of the time range, indicating increased uncertainty in the estimates.

This pattern suggests that beef prices during this timeframe were shaped by seasonal trends, retailer pricing strategies, and possible supply chain fluctuations. The observed variability and eventual stabilization highlight the dynamic nature of the market and emphasize the importance of tracking temporal pricing trends to better understand market behavior and inform retailer or policy decisions on pricing strategies and affordability.

```{r}
#| label: fig-current_vs_old_price
#| fig-cap: "Relationship Between Old and Current Beef Price Levels"
#| echo: false
#| warning: false
#| message: false

# Create price levels for old_price and current_price with finer granularity
beef_data <- beef_data %>%
  mutate(
    old_price_level = cut(old_price, breaks = seq(0, max(old_price, na.rm = TRUE), by = 2), include.lowest = TRUE),
    current_price_level = cut(current_price, breaks = seq(0, max(current_price, na.rm = TRUE), by = 2), include.lowest = TRUE)
  )

# Count occurrences of price levels
price_level_counts <- beef_data %>%
  count(old_price_level, current_price_level, name = "count")

# Create the heatmap
ggplot(data = price_level_counts, aes(x = old_price_level, y = current_price_level, fill = count)) +
  geom_tile(color = "lightgrey") +
  scale_fill_gradient(low = "lightgrey", high = "red", name = "Frequency") +
  labs( x = "Old Price Level", y = "Current Price Level") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```

@fig-current_vs_old_price presents a heatmap showing the relationship between old and current beef prices, illustrating how pricing has changed over time across various products. The x-axis represents old price levels, and the y-axis represents current price levels, with each cell indicating the frequency of products at specific combinations of these levels. The intensity of the cell color, ranging from light red to dark red, reflects the density of observations, as described by the legend on the right.

The heatmap shows a clear diagonal pattern, indicating that higher old price levels correspond closely to higher current price levels. This alignment highlights a strong positive correlation between historical and current prices, suggesting that most products have undergone proportional pricing adjustments. The darker cells along the diagonal represent the most frequent combinations of old and current prices, pointing to consistent adjustments influenced by factors such as market stability, inflation, or standardized vendor practices.

In contrast, off-diagonal cells, which are lightly shaded or empty, represent rare occurrences of significant deviations from the proportional trend. These sparse areas indicate that sharp discounts or large price increases are infrequent, reinforcing the observation that pricing tends to remain stable and closely tied to historical values.

Overall, the heatmap provides an aggregated view of the consistency in beef pricing across different conditions. By grouping pricing data into distinct levels, it visually emphasizes the alignment between old and current prices, highlighting systematic adjustments and the rarity of irregular deviations, which may be influenced by vendor strategies or external market factors.

```{r}
#| label: fig-unit_price_distribution
#| fig-cap: "Distribution of Unit Prices"
#| echo: false
#| warning: false
#| message: false

ggplot(beef_data, aes(x = price_per_unit)) +
  geom_density(fill = "lightgrey", color = "red", , linewidth = 0.8, alpha = 0.5, bw = 0.5) +
  labs(x = "Unit Price ($ per 100 grams)", y = "Density") +
  theme_minimal()

```

@fig-unit_price_distribution displays the distribution of unit prices for beef, measured in \$ per 100 grams. The x-axis shows unit prices, while the y-axis represents density, indicating the proportion of observations across different price ranges. The grey area under the density curve highlights the relative concentration of unit prices, while the red curve provides a smoothed estimate of the overall distribution.

A notable feature of this figure is the high density near \$0, indicating that a large number of observations in the dataset have very low unit prices. This concentration could reflect promotions, bulk discounts, or potential data issues that may require further review. Beyond this initial spike, the density decreases sharply, with smaller secondary peaks appearing around \$2, \$4, and \$6 per 100 grams. These peaks may correspond to different pricing tiers influenced by factors such as product quality, cut type, or retailer-specific strategies.

The distribution is heavily right-skewed, with the majority of observations clustered at lower price points and fewer cases of higher-priced beef products. This pattern suggests that the market is dominated by affordable beef options catering to a broad consumer base, while premium products occupy a smaller share. The presence of multiple peaks indicates segmentation within the market, driven by variations in product attributes or retailer pricing approaches. This highlights the coexistence of budget-friendly and premium offerings, reflecting diverse consumer preferences and pricing strategies in the Canadian grocery market.

## Modeling

```{r}
#| label: tbl-modelresults
#| tbl-cap: "Beef model results"
#| echo: false
#| warning: false
#| message: false

modelsummary::modelsummary(
  list(
    "Beef model (Bayesian)" = beef_model
  ),
  statistic = "mad",
  fmt = 2
)

```

@tbl-modelresults presents the outcomes of the Bayesian model used to analyze beef prices, highlighting parameter estimates and diagnostic measures. The model evaluates the relationship between the current price of beef and predictors, including the old price, vendor, and month of observation.

The estimated intercept of -0.37, while seemingly unusual, serves as a reference point within the model and should be interpreted in the context of the predictors. The "month" coefficient of -0.01 indicates a small downward trend in current prices over time, possibly reflecting seasonal influences or market adjustments. The "old_price" coefficient, at 0.81, demonstrates a strong positive relationship, indicating that higher historical prices correspond to proportionally higher current prices, suggesting consistent pricing patterns over time. Additionally, the "vendorWalmart" coefficient of 0.56 shows that Walmart's beef prices are, on average, higher than those at T&T, consistent with observed vendor-specific pricing strategies.

In terms of model fit, the R-squared value of 0.945 and adjusted R-squared of 0.944 indicate that the model accounts for a significant portion of the variability in beef prices. Metrics such as the negative log-likelihood (-4349.672) and expected log pointwise predictive density (ELPD) of -4354.7 further support the model’s ability to capture key patterns in the data. Predictive measures, including the leave-one-out information criterion (LOOIC) and Widely Applicable Information Criterion (WAIC), both approximately 8709, confirm the model’s reliability in making predictions. The root mean square error (RMSE) of 1.02 reflects minimal average deviation between predicted and observed values, underscoring the model’s accuracy.

The results demonstrate a strong, consistent relationship between historical and current pricing while highlighting differences in pricing strategies between vendors. Using a Bayesian framework allows for uncertainty to be incorporated into the analysis, providing robust parameter estimates. The high explained variance and reliable predictive performance affirm the model’s effectiveness in analyzing and forecasting beef price trends, offering a clear understanding of market behaviors for both consumers and stakeholders.

# Discussion {#sec-discussion}

## Interpretation of Findings

The findings of this study provide a detailed look into the factors influencing beef pricing in the Canadian grocery market. Using Bayesian linear regression, the results demonstrate that historical pricing (old_price) and vendor-specific strategies are significant predictors of current prices. The strong positive relationship between old_price and current_price suggests a high level of consistency in pricing practices, likely influenced by factors such as inflation or vendor strategies. Walmart and T&T exhibit distinct pricing approaches, with Walmart showing more consistent pricing while T&T displays greater variability, possibly due to its focus on specialty goods catering to specific cultural preferences. Seasonal trends, represented by the month variable, indicate small but noticeable temporal price variations, likely linked to supply and demand fluctuations throughout the year.

Visualizations in the previous section (@sec-result), along with statistical summaries, reinforce these findings. The heatmap in @fig-current_vs_old_price demonstrates a strong alignment between old and current prices, highlighting the significant influence of historical costs on current pricing. Factors such as production expenses, inflation, and market demand appear to affect historical and current prices in similar ways. The high R-squared value of the Bayesian model (@tbl-modelresults) further confirms that the selected predictors capture the majority of variation in beef prices, emphasizing their importance. Additional observations can be drawn from these results, as discussed below.

## Vendor-Specific Pricing Strategies

A key observation is the clear difference in pricing strategies between Walmart and T&T. Walmart’s pricing strategy, as reflected by its narrower boxplot range (@fig-price_difference_by_vendor), emphasizes consistency and predictability, aligning with its branding as a retailer offering everyday low prices [@citeWalmartLowPrice]. This approach likely appeals to price-sensitive consumers seeking stability and affordability. In contrast, T&T shows a wider range of price differences, which may reflect a dynamic pricing strategy tailored to its specialty products, diverse supply chain, and specific customer demographic [@citeTandT]. The variability in T&T’s pricing could stem from promotional efforts, targeted price differentiation, or a wider range of product qualities and types.

Understanding these strategies is essential for interpreting pricing data. Walmart’s standardized pricing is likely to attract a broad customer base, while T&T’s variability might appeal to niche markets looking for specialty goods. Future research could expand on these findings by incorporating product-level details, customer demographics, or promotional data to better understand the drivers behind these pricing differences.

## Price Stability and Market Forces

The study highlights a general stability in beef pricing, with adjustments largely proportional to historical prices. This stability may suggest a well-functioning market where historical prices act as an anchor for setting current prices, potentially influenced by supplier contracts or steady production costs. The modest decline in prices observed in certain months could reflect seasonal promotions or changes in demand, driven by factors like holiday sales [@citeHoliday] or shifts in meat consumption habits.

The clustering of prices at the lower end of the range suggests that the majority of beef products cater to value-conscious consumers, which may reflect broader economic trends or retailer strategies to maintain affordability. Larger players like Walmart might use economies of scale to keep prices competitive, shaping market dynamics as a result. To build on these findings, future studies could investigate how external events, such as economic downturns or supply chain disruptions [@citeSupplyChain], affect this pricing stability and whether similar patterns are observed in other product categories.

## Cultural Preferences and Product Differentiation

Cultural preferences play a significant role in beef pricing, as evidenced by the differences between T&T and Walmart. T&T’s pricing patterns, which are more varied, may reflect its focus on serving an Asian customer base with specific culinary needs [@citeCulture]. The diversity in its product cuts and grades could contribute to these patterns, as sourcing requirements and preparation methods may differ based on cultural preferences. This may lead to higher variability in prices.

For policymakers and retailers addressing food affordability, these findings underscore the importance of considering cultural factors in consumption patterns. Retailers like T&T, which cater to specific demographic groups, might need tailored pricing strategies, while larger chains like Walmart could focus on maintaining uniform pricing to appeal to a broader market.

## Promotional Strategies and Consumer Behavior

Promotional strategies also play a role in shaping beef prices. T&T’s greater variability could reflect frequent promotional activities aimed at specific customer segments. Promotions may be used to move inventory, introduce new products, or compete with other retailers [@citePromotion]. This contrasts with Walmart’s approach, which prioritizes stable pricing over frequent discounts.

Consumer preferences likely influence these strategies. Price-sensitive shoppers may gravitate toward Walmart for its predictable pricing, while those seeking specialty cuts or products may prefer T&T, even with its price fluctuations. Future research could examine the impact of promotions by analyzing temporal pricing data alongside promotional calendars or sales events to better understand how short-term discounts affect pricing patterns and consumer loyalty.

## Weaknesses and Future Directions

While this study provides a useful analysis of beef pricing dynamics, it has some limitations. First, the dataset includes only two vendors, Walmart and T&T, which may not fully represent the diversity of the Canadian grocery market. Expanding the study to include additional retailers, such as discount chains, premium grocers, or independent stores [@citeBrand], could offer a broader perspective. Additionally, the analysis does not account for factors like promotions, product quality, or customer loyalty programs [@citeProgram], which could significantly influence pricing. Future models incorporating these variables could provide a deeper understanding of pricing behavior.

The assumption of a linear relationship between predictors and the outcome may oversimplify the complexity of real-world pricing. Future studies could explore more flexible modeling techniques, such as non-linear models or machine learning approaches, to better capture these relationships. Incorporating external data sources, such as economic indicators, weather patterns, or detailed sales records, could further validate and enrich the findings.

The assumptions of constant variance and normality of residuals may not fully apply to pricing data, which often show heteroscedasticity or other deviations. Using more robust regression methods or heteroscedasticity-consistent estimators could enhance the model's accuracy and reliability. Future research could investigate how changes in consumer preferences, such as the growing interest in plant-based alternatives, influence beef pricing trends, offering a deeper understanding of shifting market dynamics.

\newpage

\appendix

# Appendix {-}

# Data details  {#sec-data_details}

## Cleaning methods

In the data cleaning process, the objective was to load raw product and transaction data, combine them, filter and transform relevant columns, and save the cleaned dataset for further analysis. The process started by loading two CSV files: "hammer-4-product.csv" and "hammer-4-raw.csv." These files contained details about various products and related transactions. After loading the data, the datasets were merged to create a unified dataset, providing more complete product information, as shown in @tbl-merge_data.

```{r}
#| label: tbl-merge_data
#| tbl-cap: "Raw Merged Data"
#| echo: false
#| warning: false
#| message: false

merge_data %>%
  head() %>%
  kable(
    col.names = c(
      "Time", 
      "Vendor", 
      "Product ID", 
      "Product Name", 
      "Brand", 
      "Current Price", 
      "Old Price", 
      "Units", 
      "Price per Unit"
    ),
    booktabs = TRUE
  )

```

The two datasets were merged using an inner join on the `product_id` and `id` columns. This approach ensured that only relevant columns were retained, such as product details (`product_name`, `brand`), vendor information, and pricing (`current_price`, `old_price`, and `price_per_unit`). The aim was to keep only the attributes necessary for further analysis.

After merging the datasets, the focus shifted to creating a subset, `ppu_data`, specifically for price-per-unit data (`price_per_unit`). This subset included only records from vendors Walmart and T&T, with product names containing "beef," narrowing the dataset to beef-related items. Only the `vendor` and `price_per_unit` columns were selected for this subset, which was saved as a separate parquet file for further analysis.

The main cleaning process resulted in the creation of the `cleaned_data` dataset (@tbl-clean_data), which included only records from Walmart and T&T. Key columns were retained, such as transaction time (`nowtime`), vendor, product pricing, and product details. Additional transformations ensured the dataset was ready for analysis. For instance, the `nowtime` column was parsed to extract `year`, `month`, and `day` for a more detailed breakdown of transaction timing. The `current_price` and `old_price` columns were converted to numeric values using `parse_number()` to handle any non-numeric characters.

```{r}
#| label: tbl-clean_data
#| tbl-cap: "Cleaned Data"
#| echo: false
#| warning: false
#| message: false

beef_data %>%
  select(vendor, current_price, old_price, product_name, price_per_unit, year, month, day) %>%
  head() %>%
  kable(
    col.names = c(
      "vendor", 
      "current_price", 
      "old_price", 
      "product_name", 
      "price_per_unit", 
      "year", 
      "month", 
      "day"
      ),
    booktabs = TRUE
  ) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(4, width = "7em")

```

The `price_per_unit` column was cleaned to ensure consistency. The dollar sign was first extracted using `str_extract()` and then removed with `str_remove()`. The resulting values were converted to numeric format to allow accurate comparisons and analysis. For cases where `price_per_unit` was missing, the `ifelse()` function assigned a default value of 0, ensuring that no missing data points interfered with subsequent operations.

To refine the dataset for beef products, the `cleaned_data` dataset was filtered to retain only rows where `product_name` contained "beef." Records with terms such as "flavour," "vermicelli," and "rice," which indicated non-beef items, were excluded. This filtering step ensured the final dataset was focused on beef-related products, reducing noise from irrelevant entries. The `nowtime` column, which was no longer required, was dropped, and any rows containing `NA` values were removed using `drop_na()`.

The cleaned data was then saved into parquet files: `ppu_data.parquet` for the price-per-unit subset and `beef_data.parquet` for the complete cleaned dataset.

\newpage

## Vendor Choice

The selection of Walmart and T&T as vendors for this analysis was based on their distinct characteristics and market coverage, offering a diverse view of beef pricing. Walmart, as a leading multinational retailer with a wide presence across North America, represents mainstream, large-scale grocery retailing. Its extensive reach and focus on standardized pricing make it a strong representative of general market trends. Including Walmart in the analysis helps capture pricing behaviors that reflect the typical shopping experience for a broad consumer base, characterized by competitive pricing and a wide product range.

In contrast, T&T Supermarket caters to a niche market, serving Asian communities and consumers looking for specialty goods that align with Asian culinary traditions. T&T's emphasis on culturally specific products, unique supply chains, and vendor relationships provides a valuable comparison to Walmart. By analyzing T&T, this study examines how cultural preferences and niche market strategies influence pricing, reflecting the demands of a distinct consumer segment and highlighting differences from broader market trends.

Including both Walmart and T&T allows this analysis to examine mainstream and culturally specific market behaviors. Walmart’s focus on scale and cost-efficiency contrasts with T&T’s specialization and cultural targeting, enabling meaningful comparisons in beef pricing strategies across different retail contexts. This approach provides a more detailed understanding of the factors shaping beef prices in diverse settings, highlighting variations in consumer preferences, pricing strategies, and market positioning.

\newpage

## Price per unit

To clean the `price_per_unit` variable, I first extracted the numerical values using `str_extract()`, capturing valid price amounts formatted with a dollar sign (`\\$[0-9\\.]+`), as shown in @tbl-price_per_unit-1. This step ensured that only price-related information was retained, removing any extraneous text or symbols from the original string.

I then removed the dollar sign using `str_remove("\\$")` to prepare the extracted values for numerical operations. After this, the cleaned strings were converted into a numeric format using `as.numeric()`, enabling quantitative analysis.

To address missing values, I used `ifelse(is.na(price_per_unit), 0, price_per_unit)`, replacing `NA` values in the `price_per_unit` column with `0`. This ensured that every row had a value for `price_per_unit`, preventing disruptions during further analysis. While assigning zero helped maintain dataset continuity, this approach assumes that missing values are negligible, which may require additional context during interpretation. The cleaned `price_per_unit` column is shown in @tbl-price_per_unit-2.

```{r}
#| label: tbl-price_per_unit
#| tbl-cap: "Price per Unit Data for TandT and Walmart"
#| tbl-subcap: ["Raw Data", "Cleaned Data"]
#| echo: false
#| warning: false
#| message: false
#| layout-ncol: 2

ppu_data %>%
  filter(vendor == "TandT") %>%
  head(6) %>%
  bind_rows(
    ppu_data %>%
      filter(vendor == "Walmart") %>%
      head(6)
  ) %>%
  kable(
    col.names = c("Vendor", "Price per Unit"),
    booktabs = TRUE
  )

beef_data %>%
  filter(vendor %in% c("TandT", "Walmart")) %>%
  select(vendor, price_per_unit) %>%
  group_by(vendor) %>%
  summarise(price_per_unit = list(head(price_per_unit))) %>%
  tidyr::unnest(price_per_unit) %>%
  kable(
    col.names = c("Vendor", "Price per Unit"),
    booktabs = TRUE
  )

```

\newpage

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheck, a posterior predictive check is performed to assess the model's ability to reproduce the observed data. The plot compares the observed data distribution (shown in dark lines) with simulated datasets from the posterior (represented by light grey lines). This check evaluates how well the model captures the underlying patterns in the data. The close alignment between the observed data and the simulated posterior distributions indicates that the model effectively reflects the data's characteristics. Specifically, the observed peaks and troughs are well represented by the posterior samples, demonstrating the model's ability to capture key features such as the overall shape and spread of the distribution. Additionally, the variability in the posterior predictive samples aligns with the observed variability, suggesting no significant issues with model fit.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheck
#| fig-cap: "Posterior prediction check result"

# Posterior predictive check
pp_check(beef_model, plotfun = "dens_overlay")

```

\newpage

In @fig-posteriorvsprior, the posterior and prior distributions for each parameter are compared. The posterior distributions (on the left) are more concentrated than the priors (on the right), showing how the data has updated the initial parameter estimates. For example, the posterior distribution for the intercept is much narrower than its prior, indicating that the data has strongly informed the estimate of the baseline price level. Similarly, the posterior distributions for the other parameters (month, old_price, sigma, and vendorWalmart) are less dispersed than the priors, reflecting a meaningful reduction in uncertainty.

The posterior intervals are particularly narrow for the intercept and old_price parameters, suggesting that the data has provided substantial information about these effects. This comparison demonstrates that the priors were appropriately weak, allowing the data to play a dominant role in refining the parameter estimates. The results highlight how the model effectively incorporates data to improve the precision of the estimates.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-posteriorvsprior
#| fig-cap: "Comparing the posterior with the prior"

# Comparing posterior with prior
posterior_vs_prior(beef_model, color_by = "parameter") +
  theme_minimal() +
  scale_fill_grey() +
  scale_color_grey() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

\newpage

## Diagnostics

In @fig-trace, a trace plot is presented, showing the sampled values for each parameter across the MCMC iterations. The trace plot is used to evaluate whether the chains have converged to a stationary distribution. In these plots, the chains for each parameter are well mixed, with no visible trends, indicating that the MCMC algorithm has effectively explored the parameter space. The absence of upward or downward drift suggests that the chains are consistently sampling from the target distribution, providing strong evidence of convergence.

Each parameter’s chains oscillate around a stable mean, with significant overlap among the four chains. This consistent mixing is observed across all parameters, including the intercept, month, old price, vendorWalmart, and sigma. The overlap and stability across chains indicate that the model has achieved convergence, with all chains sampling from similar regions of the posterior distribution.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-trace
#| fig-cap: "Trace plot"

# Trace plot
plot(beef_model, plotfun = "trace") + theme_minimal()

```

\newpage

In @fig-rhat, an Rhat plot is presented to assess model convergence. The Rhat statistic (or potential scale reduction factor) compares the variance between chains to the variance within chains, with values close to 1 indicating convergence. In this plot, all Rhat values for the parameters are very close to 1 and below the threshold of 1.05, confirming that the chains have converged.

The low Rhat values indicate that the chains are consistent and in agreement about the posterior distributions. This suggests that the model's parameter estimates are stable and that the MCMC algorithm has effectively converged. As a result, we can be confident in the reliability of the parameter estimates produced by the Bayesian model.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-rhat
#| fig-cap: "Rhat plot"

# Rhat plot
plot(beef_model, plotfun = "rhat") + theme_minimal()

```

\newpage

# Idealized Methodology for a Survey on Beef Pricing {#sec-survey}

## Overview

To enhance the quantitative analysis in this paper, an idealized survey methodology could capture consumer behavior and perceptions related to beef pricing at Walmart and T&T. The survey would aim to identify factors influencing purchasing decisions, perceptions of price fairness, and preferences for vendor-specific attributes. This approach would provide a broader understanding of the factors shaping beef pricing dynamics in the Canadian grocery market.

## Sampling Approach

A **stratified random sampling** method would be used to ensure representation across key demographic groups, including age, income levels, and cultural background. This approach aims to reflect the diversity in shopping preferences and behaviors, particularly concerning beef pricing in the Canadian grocery market. Stratified random sampling would enable the survey to capture differences in purchasing decisions among various demographic segments and facilitate detailed comparisons between consumer groups, providing a clearer understanding of pricing patterns in diverse retail settings.

1. **Region**: The sample would include both urban and rural shoppers across Canada to account for differences in population density and shopping patterns. Urban consumers are likely to have easier access to Walmart and T&T locations, while rural shoppers may rely on fewer options or local vendors. This regional distinction is important for understanding how geography influences purchasing behavior, particularly regarding access, convenience, and sensitivity to price.

2. **Vendor Familiarity**: Respondents would be grouped into three categories: regular Walmart shoppers, regular T&T shoppers, and those who shop at both retailers. Walmart shoppers might focus on consistent pricing and product availability, while T&T shoppers may prioritize variety and specialty items that align with cultural preferences. Including consumers who shop at both stores would provide a comparative perspective on how purchasing behavior shifts between general and specialty retail settings, highlighting the role of brand familiarity and loyalty in shaping beef-buying decisions.

3. **Income Brackets**: Respondents would be grouped into low-, middle-, and high-income households to assess how financial resources influence beef purchasing behaviors. Lower-income households are likely to emphasize affordability and may be more sensitive to price changes and promotions. Middle-income households might balance cost with considerations of quality, while high-income households could prioritize premium quality, showing less sensitivity to price. This stratification allows for a detailed analysis of how economic factors impact both the frequency and type of beef products purchased at Walmart and T&T, helping to identify variations in price elasticity across income levels.

A total sample size of approximately 1,200 respondents would be targeted, with 400 participants in each stratum (Walmart-focused, T&T-focused, and dual shoppers). This approach ensures meaningful comparisons of consumer perceptions and retailer strategies.

## Survey Structure

The survey would include a mix of **closed-ended** and **open-ended** questions.

### Question Types

1. **Demographics and Shopping Habits**  
   - Frequency of grocery shopping (e.g., weekly, bi-weekly).  
   - Preferred vendor for beef purchases, along with reasons for the preference.  
   - Average budget allocated specifically for beef purchases.

2. **Price Perception**  
   - Rating of beef price fairness on a Likert scale.  
   - Comparison of beef prices between Walmart and T&T (e.g., cheaper, equivalent, or more expensive).  
   - Sensitivity to price changes (e.g., how a 10% increase in beef prices might influence purchasing behavior).  

3. **Cultural and Quality Preferences**  
   - Importance of cultural alignment in beef products (e.g., availability of specific cuts or preparation styles).  
   - Perceptions of quality differences in beef products offered by Walmart and T&T.  
   - Willingness to pay more for products that are culturally tailored.  

4. **External Factors**  
   - Awareness of seasonal price trends and their impact on buying decisions.  
   - Influence of promotions on purchasing behavior.  
   - Adjustments made in response to supply chain disruptions (e.g., choosing alternative products or vendors).  

### Question List

1. How often do you shop for groceries?  
   - Weekly  
   - Bi-weekly  
   - Monthly  
   - Less often  

2. Which retailer do you prefer for buying beef products?  
   - Walmart  
   - T&T  
   - Both  

3. What factors influence your choice of retailer for beef purchases? (Select all that apply)  
   - Price  
   - Quality  
   - Availability of specific cuts  
   - Cultural preferences  
   - Convenience  
   - Promotions  

4. On average, how much do you spend on beef per shopping trip?  
   - Less than $20  
   - \$20 - \$50  
   - \$50 - \$100  
   - More than $100  

5. How fair do you find the current beef prices at Walmart or T&T?  
   - Very unfair  
   - Somewhat unfair  
   - Neutral  
   - Somewhat fair  
   - Very fair  

6. How would you rate the quality of beef at Walmart compared to T&T?  
   - Much lower quality  
   - Slightly lower quality  
   - About the same quality  
   - Slightly higher quality  
   - Much higher quality  

7. If beef prices increased by 10%, would you consider switching to an alternative product or retailer?  
   - Definitely would switch  
   - Probably would switch  
   - Might switch  
   - Probably would not switch  
   - Definitely would not switch  

8. How important is it that beef products match your cultural preferences (e.g., specific cuts, preparation styles)?  
   - Not important at all  
   - Slightly important  
   - Moderately important  
   - Very important  
   - Extremely important  

9. Are you willing to pay more for beef products tailored to your cultural preferences?  
   - Not willing at all  
   - Slightly willing  
   - Moderately willing  
   - Very willing  
   - Extremely willing  

10. How aware are you of seasonal price changes in beef products?  
    - Not aware at all  
    - Slightly aware  
    - Moderately aware  
    - Very aware  
    - Extremely aware  

11. How much do promotions influence your decision to purchase beef?  
    - No influence  
    - Slight influence  
    - Moderate influence  
    - Significant influence  
    - Very significant influence  

12. How do you typically respond to supply chain disruptions affecting beef availability?  
    - Purchase alternative products  
    - Purchase from a different retailer  
    - Reduce beef consumption  
    - No change in purchasing behavior  

## Recruitment Strategy

Participants would be recruited using **multichannel outreach**, including:

1. **Online Panels**: Recruitment would involve partnering with established Canadian consumer research platforms to access existing online panels. These platforms have extensive databases of participants segmented by demographics such as age, income, and geographic location, enabling targeted recruitment. Collaborating with these platforms ensures the inclusion of participants from diverse areas, spanning urban centers like Toronto and Vancouver to rural regions across the provinces. Online panels offer a quick and efficient way to reach respondents while allowing quotas to be set for representativeness based on stratification variables, such as income levels and familiarity with specific retailers.

2. **Retailer Partnerships**: Collaborating with Walmart and T&T stores for in-store recruitment would capture input directly from shoppers at the point of purchase. QR codes placed on receipts or near store exits could invite shoppers to participate by scanning with their mobile devices. This approach encourages immediate participation while the shopping experience is still fresh. Additional promotional efforts, such as in-store displays, posters, or handouts, would increase visibility, while staff could provide gentle reminders to shoppers about the survey. This strategy ensures the inclusion of active shoppers at Walmart and T&T, providing real-time feedback on beef purchasing habits and preferences.

3. **Community Outreach**: To reach underrepresented groups, particularly T&T shoppers from diverse cultural backgrounds, targeted outreach would be conducted through partnerships with cultural organizations, community centers, and local events. Collaborating with groups such as cultural associations, language schools, or ethnic community centers would help include participants who might not be reachable through online panels or in-store recruitment alone. Outreach efforts could also involve attending cultural festivals, placing advertisements in community newsletters, and utilizing social media platforms tailored to specific cultural groups. This approach ensures the inclusion of shoppers with unique cultural preferences and shopping behaviors. Engaging directly with these communities fosters trust and encourages participation, leading to a more complete understanding of how cultural factors shape beef purchasing decisions.

## Linkage to Literature

The survey design for this study is informed by established methodologies in consumer behavior and retail pricing research. By using **stratified random sampling**, the study ensures that key factors influencing purchasing decisions—such as income, cultural background, and shopping preferences—are effectively represented. This approach draws on research highlighting the importance of **representative sampling** to analyze market segmentation in diverse consumer markets [@citeSegmentation]. Stratified sampling is particularly useful for capturing differences in preferences that may arise from demographic variations, as outlined in **demographic-based segmentation theories** in consumer studies.

The adoption of **multichannel recruitment** is also important for increasing participation rates, especially when targeting a diverse population [@citeMultichannel]. Combining online recruitment with community-based efforts has been shown to improve inclusivity, reduce selection bias, and ensure adequate representation of underrepresented groups. This approach is especially relevant for a study aiming to examine pricing strategies across various consumer segments, including culturally specific shoppers who may not engage with online-only recruitment methods.

Including both **vendor-specific** and **cultural factors** in the survey design aligns with research on the influence of retail environments and cultural preferences on consumer behavior. Studies on cultural consumption patterns suggest that mainstream and culturally specialized stores influence purchasing decisions differently, based on familiarity, trust, and cultural alignment [@citeCulturalAlignment]. As a result, the stratification variables and recruitment methods are structured to capture these consumer preferences, offering a detailed understanding of how pricing dynamics vary between vendor types and cultural groups.

The focus on **vendor familiarity** builds on findings from the **brand loyalty** literature, which emphasize the role of familiarity in shaping price sensitivity and shopping behavior [@citeBranding]. Including vendor familiarity as a stratification criterion allows the survey to investigate how loyalty and perceptions of brand reliability influence beef pricing dynamics in different retail settings.

In conclusion, the survey design integrates established theories and practices from consumer behavior, market segmentation, and cultural studies. This approach ensures that the data collected is representative, thorough, and suited to addressing the research objectives regarding beef pricing dynamics in the Canadian retail market.

\newpage

# References


