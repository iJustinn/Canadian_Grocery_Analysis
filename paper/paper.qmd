---
title: "Beef Pricing Dynamics in the Canadian Grocery Market: A Comparative Analysis of Walmart and T&T"
subtitle: "Evidence of Cultural and Strategic Influences on Beef Pricing"
author: 
  - Ziheng Zhong
thanks: "Code and data supporting this analysis is available at: [Link to repository](https://github.com/iJustinn/Canadian_Grocery_Analysis.git)."
date: today
date-format: long
abstract: "This study analyzes beef pricing dynamics in the Canadian retail market, focusing on two vendors: Walmart and T&T. Using Bayesian linear regression, we found that historical pricing and vendor-specific strategies significantly influence current beef prices, with Walmart displaying more price stability and T&T showing greater variability. These findings reveal how both market-wide and vendor-specific factors shape beef pricing, offering insights that could help retailers refine their pricing strategies and support policymakers in addressing food affordability. This paper provides a clearer understanding of the interplay between cultural preferences and retail strategies in determining food prices."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
# load library
package_list <- c("tidyverse", "kableExtra", "ggplot2", "dplyr", "here", "knitr", "rstanarm", "modelsummary", "readr", "lme4", "tinytex", "reshape2", "arrow")

install_and_load <- function(package_list) {
  for (package in package_list) {
    if (!require(package, character.only = TRUE)) {
      install.packages(package)
      library(package, character.only = TRUE)
    }
  }
}

install_and_load(package_list)

# load data
ppu_data <- read_parquet(here("data", "02-analysis_data", "ppu_data.parquet"))
beef_data <- read_parquet(here("data", "02-analysis_data", "beef_data.parquet"))

# load model
beef_model <- readRDS (file = here:: here ("models/beef_model.rds"))
```



# Introduction

The pricing of grocery products, particularly beef, plays a significant role in understanding consumer behavior and market dynamics within the Canadian retail sector. Beef, as a staple of many households, exhibits complex pricing behaviors influenced by a variety of factors, including vendor strategies [@citePricingStrategies], historical pricing, and seasonal trends [@citeSeasonal]. The broader context for this study lies in exploring how large-scale retailers and specialty stores adjust their beef prices over time and how these changes reflect broader economic and cultural trends. Given the increasing concerns around food affordability and accessibility, understanding the dynamics of beef pricing is not only crucial for consumers but also for stakeholders involved in food distribution and policy-making.

This paper specifically focuses on two prominent vendors, Walmart and T&T, to examine how beef pricing varies across different types of retail environments. Walmart, as a major multinational retailer, represents mainstream [@citeWalmart], standardized pricing strategies, while T&T, catering primarily to Asian communities, represents a more specialized market segment [@citeTandT]. By analyzing data from these two vendors, this paper aims to address an important gap in understanding how cultural preferences and retail strategies influence product pricing. While previous studies have highlighted general trends in food pricing, they often overlook the nuanced differences between general retail chains and culturally specific stores. This paper fills that gap by providing an in-depth analysis of beef pricing patterns across these two distinct retail settings.

The estimand of this study is the current price of beef, determined by factors such as vendor type, historical pricing, etc. By estimating how these variables impact the current pricing, the paper aims to provide a comprehensive understanding of the pricing mechanisms that affect retail beef prices in Canada.

Using a Bayesian linear regression approach, this study examines the effect of historical pricing, vendor-specific strategies, and seasonal factors on current beef prices. The analysis finds that old prices significantly predict current pricing, indicating a high degree of price consistency. Additionally, notable differences in pricing strategies between Walmart and T&T suggest that these vendors approach their markets with distinct pricing objectives, with Walmart favoring price stability and T&T showing more variability in pricing, possibly to cater to niche preferences. The findings are significant as they reveal the underlying mechanisms of price determination in a diverse retail environment, highlighting both market-wide factors and vendor-specific influences. Such insights could be useful for retailers looking to optimize their pricing strategies and for policymakers interested in addressing food affordability concerns.

The structure of the paper is organized as follows: @sec-data outlines the data collection and cleaning process, along with a description of the outcome and predictor variables used in the analysis. @sec-model introduces the forecasting models and discusses the rationale behind choosing these models for beef pricing prediction. @sec-result then presents the main findings, including a breakdown of vendor-level pricing effects and seasonal trends. Finally, @sec-discussion interprets the results, highlighting significant trends, comparing vendor strategies, and discussing potential limitations of the analysis.



# Data {#sec-data}

This project is motivated and guided by Rohan Alexander and his book [@citeTbook]. Data used in this paper was cleaned, analyzed and modeled with the programming language R [@citeR]. Also with support of additional packages in R: `readr` [@citeReadr], `ggplot2` [@citeGgplot2], `tidyverse` [@citeTidyverse], `dplyr` [@citeDplyr], `here` [@citeHere], `knitr` [@citeKnitr], `kableExtra` [@citeKableExtra], `rstanarm` [@citeRstanarm], `modelsummary` [@citeModelsummary], `lme4` [@citeLme4], `tinytex` [@citeTinytex], `reshape2` [@citeReshape2], `arrow` [@citeArrow].

## Source

The dataset used for this research was sourced from Hammer, a publicly available repository designed to provide pricing data from various retail chains. The dataset comprises detailed information on product attributes, such as product name, vendor, current price, old price, units available, and additional details like the month of certain price. The dataset's broader context is centered on consumer pricing trends across different vendors, helping to understand how factors like vendor type, previous pricing, and seasonal changes influence current prices. This information is pivotal for examining market behaviors and assessing pricing strategies in retail environments.

The dataset variables include several categorical and numerical components. Key variables such as ‘vendor’, which identifies the retailer (e.g., Walmart, Galleria), and ‘product_name’, which details the item, are crucial for understanding distribution channels. Variables like ‘current_price’ and ‘old_price’ offer insights into pricing dynamics, enabling analyses of price changes over time. Additionally, temporal variables such as ‘month’ allow for the identification of seasonal variations in pricing. Summary statistics, along with graphs for each of these variables, help illustrate their distributions and relationships. Graphs have been included to show the frequency distribution for vendors, trends in price changes, and comparisons between old and current prices. Relationships among variables like ‘vendor’ and ‘current_price’ have been highlighted to give a comprehensive view of the dataset.

There were other potential datasets available for this analysis, such as proprietary retail data sources or other consumer purchasing databases. However, they were not selected due to restrictions on data availability, licensing requirements, or lack of detail in specific product-level attributes. The Hammer dataset was chosen as it provides granular pricing data that is crucial for understanding product-level trends across multiple vendors. The dataset also allowed for the construction of new variables, such as the calculated ‘price_per_unit’, which enabled more meaningful comparisons between products. High-level data cleaning included handling missing values in the ‘old_price’ variable by replacing them with the ‘current_price’, ensuring the analysis was consistent and complete.

## Measurement

The process of measurement in this research involves translating real-world phenomena into quantifiable data entries within the dataset. For instance, consumer purchasing behavior, influenced by factors such as vendor type, pricing history, and seasonal changes, has been captured through variables like ‘vendor’, ‘current_price’, and ‘month’. The ‘vendor’ variable serves as an identifier of the source of the product, which helps to provide insights into how different retail environments may affect pricing strategies. The ‘current_price’ and ‘old_price’ variables reflect pricing trends and allow us to measure the temporal changes in consumer costs, thereby linking economic activities to specific data points.

The temporal dimension, captured through the ‘month’ variable, enables us to measure the impact of seasonal patterns on pricing. Constructed variables such as ‘price_per_unit’ provide a standardized measurement that allows comparisons across different products, accounting for varying package sizes or quantities. This transformation from abstract consumer behaviors and retail dynamics into structured data ensures that the analysis remains rooted in real-world market phenomena, thereby enabling a more nuanced understanding of pricing behavior and trends across different vendors.

## Outcome variables
The outcome variable for this study, current_price, serves as the key focus of analysis in understanding product pricing dynamics. This section provides a structured overview of the current_price variable, including its distribution and any observed trends, supported by both summary statistics and visualizations. The aim is to offer a clear understanding of how product prices vary and what factors may influence those variations.

### Current Price
The outcome variable in this study is current_price. This variable represents the price of the product at the time of data collection and is central to understanding the effects of various factors on product pricing. By modeling current_price, we aim to explore how factors such as historical pricing, vendor type, and seasonal influences impact current market prices. This variable is crucial for determining the pricing dynamics employed by different vendors and how those strategies affect consumer costs.

To provide a comprehensive view of the outcome variable, Here's a table for easier understanding (@tbl-current_price). This table provides the minimum, maximum, mean, median, and standard deviation of the current_price variable, offering insights into the overall distribution and variability in product prices.

```{r}
#| label: tbl-current_price
#| tbl-cap: "Summary statistics for the outcome variable (current_price)"
#| echo: false
#| warning: false
#| message: false

outcome_summary <- beef_data %>%
  summarise(
    Statistic = c("Min", "Max", "Mean", "Median", "Standard Deviation"),
    Value = c(
      min(current_price, na.rm = TRUE),
      max(current_price, na.rm = TRUE),
      mean(current_price, na.rm = TRUE),
      median(current_price, na.rm = TRUE),
      sd(current_price, na.rm = TRUE)
    )
  )

outcome_summary %>%
  kable(
    col.names = c("Statistic", "Value"),
    booktabs = TRUE
  )
```

In addition to the summary table, the distribution of current_price is visualized through a histogram (@fig-current_price), highlighting common price ranges and the overall spread. This visualization helps to identify any skewness or clustering in the data, which may indicate specific pricing patterns. Together, these tables and graphs provide a comprehensive understanding of the outcome variable, offering a detailed view of how product prices vary across different vendors and over time.

```{r}
#| label: fig-current_price
#| fig-cap: "Boxplot of the distribution of current prices"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 5

ggplot(beef_data, aes(y = current_price)) +
  geom_boxplot(fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  labs(y = "Current Price (in $)") +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

```

The boxplot (@fig-current_price) presented above provides a detailed summary of the distribution of current_price for the products in the dataset. Boxplots are useful visualization tools for understanding the spread, central tendency, and overall variability of continuous data. In this case, the boxplot helps in identifying key features such as the median price, the interquartile range (IQR), and any potential outliers that may exist in the pricing data.

The median, represented by the horizontal line within the box, provides an indication of the central price of products in the dataset, highlighting where the bulk of prices are situated. The box represents the IQR, showing where the middle 50% of data points lie, thus giving insights into price concentration. The whiskers, extending from the box, represent the range within which most prices fall, excluding any extreme values or outliers. No outliers were visibly identified in this boxplot, which suggests that most product prices are consistently within a particular range.

The flat shape of the boxplot with a wide range of the IQR indicates low variability in current product prices. The relatively small difference between the lower and upper bounds of the box implies that the pricing of the products is consistent, with most prices concentrated around the median. This consistency may suggest that vendors are using similar pricing strategies or that there is limited differentiation in the types of products sold across vendors. Overall, the boxplot is a valuable tool for summarizing and communicating the underlying distribution of current_price, which aids in understanding the dynamics of pricing across different vendors.

## Predictor variables
The predictor variables in this study—month, old_price, and vendor—each play an important role in explaining variations in current_price. This section outlines how these variables potentially influence pricing, with a focus on capturing temporal patterns, historical effects, and vendor-specific pricing strategies. The summary tables and visual analyses help contextualize the impact of each predictor on the outcome, providing a broad understanding of the pricing dynamics within the dataset.

### Month
The month variable is used as a predictor to capture potential seasonal influences on pricing. By including month, we can observe if specific times of the year are associated with higher or lower prices. This is particularly important for identifying temporal patterns in pricing, which can be influenced by factors such as holidays, sales events, or seasonal demand changes. Table (@tbl-month_summary) provides a summary of the observations for each month, showing how frequently each month appears in the dataset. This information can help highlight any periods with higher or lower data collection frequency, which could influence the interpretation of seasonal pricing effects.

```{r}
#| label: tbl-month_summary
#| tbl-cap: "Summary statistics for the predictor variable (month)"
#| echo: false
#| warning: false
#| message: false

month_summary <- beef_data %>%
  group_by(month) %>%
  summarise(
    Count = n()
  )

month_summary %>%
  kable(
    col.names = c("Month", "Count"),
    booktabs = TRUE
  )

```

### Old Price
old_price serves as another key predictor variable, representing the historical price of a product. This variable helps gauge the effect of historical pricing on current pricing strategies, indicating whether a product has undergone discounts or price hikes. Table (@tbl-old_price_summary) provides a summary of key statistics for old_price, including minimum, maximum, mean, median, and standard deviation. Understanding the distribution of old_price helps us assess whether historical prices significantly differ from current prices, and whether pricing adjustments (e.g., discounts) have been applied uniformly across products. The relationship between old_price and current_price is visually explored in Chart 4, which helps understand the influence of past pricing decisions on current prices.

```{r}
#| label: tbl-old_price_summary
#| tbl-cap: "Summary statistics for the predictor variable (old_price)"
#| echo: false
#| warning: false
#| message: false

old_price_summary <- beef_data %>%
  summarise(
    Statistic = c("Min", "Max", "Mean", "Median", "Standard Deviation"),
    Value = c(
      Min = min(old_price, na.rm = TRUE),
      Max = max(old_price, na.rm = TRUE),
      Mean = mean(old_price, na.rm = TRUE),
      Median = median(old_price, na.rm = TRUE),
      `Standard Deviation` = sd(old_price, na.rm = TRUE)
  )
)

old_price_summary %>%
  kable(
    col.names = c("Statistic", "Value"),
    booktabs = TRUE
  )

```

### Vendor
The vendor variable is an important categorical predictor that differentiates pricing behavior across different retail chains. It allows us to analyze how pricing strategies vary among vendors such as Walmart and Galleria. Table (@tbl-vendor_summary) shows the count of observations for each vendor, allowing us to compare how frequently data was collected for each retail chain. This helps in understanding the representation of each vendor within the dataset and assessing whether certain vendors may have a stronger influence on the overall analysis. Chart 2, which shows the price difference by vendor, provides insights into how different vendors adjust their pricing strategies, offering valuable comparisons among them. Additionally, Chart 3 presents the average current_price over time, broken down by vendor, providing a clearer picture of how vendor-based strategies influence pricing trends.

```{r}
#| label: tbl-vendor_summary
#| tbl-cap: "Count of observations for each vendor"
#| echo: false
#| warning: false
#| message: false

vendor_summary <- beef_data %>%
  group_by(vendor) %>%
  summarise(
    Count = n()
  )

vendor_summary %>%
  kable(
    col.names = c("Vendor", "Count"),
    booktabs = TRUE
  )

```

# Model {#sec-model}

Background details and diagnostics are included in [Appendix -@sec-model-details].

## Overview

To model the current price of beef, $y_i$, at time $i$, we use a Bayesian linear regression model implemented with the `stan_glm` function in the R package `rstanarm`. The response variable, $y_i$, represents the current price of beef in dollars. Our predictors include $x_1$, $x_2$, and $x_3$, which represent the month, old price, and vendor, respectively. Each component of the model is defined and justified below.

## Set-up

Define $y_i$ as the current price of beef at time $i$, measured in dollars. Let $x_1$, $x_2$, and $x_3$ represent the predictors: $x_1$ is the month (categorical variable), $x_2$ is the old price, and $x_3$ is the vendor (categorical variable).

\begin{align}
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i}
\end{align}

In this model:
- $\alpha$ represents the intercept term, capturing the baseline price of beef.
- $\beta_1$ corresponds to the effect of the month on the current price, allowing us to capture seasonal variations that may impact beef pricing. The month is treated as a categorical variable, acknowledging that different months can bring different demand or supply effects due to holidays, weather, or other seasonal factors.
- $\beta_2$ represents the effect of the old price on the current price. This allows us to account for price inertia or trends where past pricing influences current pricing.
- $\beta_3$ represents the effect of the vendor, also treated as a categorical variable. Different vendors may have distinct pricing strategies, and including vendor as a categorical predictor helps us capture this vendor-specific pricing variation.

We assume normal priors for the model coefficients and intercept, with mean 0 and standard deviation 2.5:

\begin{align}
\alpha &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5)
\end{align}

These priors are chosen to be weakly informative, allowing the data to speak for itself while still providing a reasonable range for the coefficients based on prior expectations. Specifically, a standard deviation of 2.5 reflects our expectation that most reasonable effects should fall within a plausible range without being overly restrictive.

For the residual standard deviation, $\sigma$, we assume an Exponential(1) prior:

\begin{align}
\sigma &\sim \text{Exponential}(1)
\end{align}

This prior reflects our belief that the standard deviation should be positive and allows flexibility, while preferring smaller values over larger ones, consistent with the expectation of modest variability around the mean prediction.

We run the model in R [@citeR] using the `rstanarm` package of @citeRstanarm. We use the default priors from `rstanarm`.

## Justification

The choice of predictors is well-balanced in terms of complexity and appropriateness for this scenario. By including month and vendor as categorical variables, we acknowledge the significant impact that both seasonal changes and vendor-specific factors can have on the current price of beef. The inclusion of the old price reflects the idea of price inertia, where historical prices are likely to influence current pricing trends.

The model is neither overly simplistic nor unnecessarily complex: it captures important predictors without adding extraneous complexity that could lead to overfitting. Month and vendor are treated as categorical variables rather than grouping by more arbitrary categories, which maintains the expressiveness of our model while being parsimonious.

The model is implemented using `stan_glm` from the `rstanarm` package, a high-level interface to Stan for Bayesian modeling. Stan provides powerful sampling algorithms, making it an appropriate tool for fitting our Bayesian model efficiently, ensuring robust convergence and accurate posterior estimation.

### Assumptions and Limitations
- **Linearity**: The model assumes a linear relationship between the predictors and the response variable. This may be a limitation if the true relationship is nonlinear.
- **Normality of Residuals**: The residuals are assumed to follow a normal distribution. If this assumption does not hold, it could bias the model predictions.
- **Priors**: We used weakly informative priors to allow flexibility. However, if we had prior knowledge of specific pricing patterns, more informative priors could be used for better inference.

### Validation and Diagnostics
- **Posterior Predictive Checks**: We performed posterior predictive checks to verify that the model adequately captures the variation in the data. These checks involve comparing simulated data from the posterior distribution to the observed data to check for any discrepancies.
- **Convergence**: Model convergence was assessed using trace plots and the R-hat statistic, with all values being close to 1, indicating successful convergence.
- **Alternative Models**: We also considered fitting simpler linear models that did not include the vendor or seasonal components. These models showed significantly lower predictive performance, indicating the importance of including both the vendor and seasonal factors for accuracy.

In summary, the chosen model provides a comprehensive yet interpretable understanding of how different factors influence the current price of beef. The Bayesian approach allows us to incorporate uncertainty and prior beliefs, while our specific choice of priors and predictors ensures that the model is well-suited for the available data and research questions.



# Results {#sec-result}

## Charting

```{r}
#| label: fig-current_price_distribution
#| fig-cap: "Distribution of Current Prices"
#| echo: false
#| warning: false
#| message: false

ggplot(beef_data, aes(x = current_price)) +
  geom_histogram(binwidth = 1, fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  geom_density(aes(y = ..count..), color = "red", size = 0.8) +
  labs(x = "Current Price (in $)", y = "Frequency") +
  theme_minimal()

```

Figure 2 (@fig-current_price_distribution) presents the distribution of current beef prices in the dataset, offering insights into the range and frequency of beef pricing. The horizontal axis represents the price in dollars, ranging from 0 to approximately 25, while the vertical axis indicates the frequency, or the number of observations, within each price range. The grey bars illustrate the frequency distribution, showing how beef prices are spread across different price levels.

The histogram indicates that the most frequent price range is between \$5 and \$10, with a notable peak in the frequency around \$7 to \$8. This suggests that a significant proportion of beef products are priced within this range, making it a central pricing cluster in the market. Additionally, there are smaller peaks around \$13 and \$15, hinting at secondary groupings where beef prices are relatively common. The declining frequency beyond \$15 suggests fewer beef products are priced in the higher range, indicating that higher prices are less typical in this dataset.

The overlaid red line represents a smoothed density curve that helps to visualize the general shape and distribution trend of the prices. The curve follows the histogram closely, showing a skewed distribution with a concentration towards the lower prices, and tails off as prices increase. This pattern suggests that while lower-priced beef products are more common, higher prices are less frequent, potentially indicating a general preference or affordability constraint for lower-cost beef among consumers. The presence of multiple peaks could also imply different pricing tiers, perhaps influenced by factors such as beef quality or specific product types.

```{r}
#| label: fig-price_difference_by_vendor
#| fig-cap: "Price Difference by Vendor"
#| echo: false
#| warning: false
#| message: false

beef_data <- beef_data %>%
  mutate(price_difference = old_price - current_price)

ggplot(beef_data, aes(x = vendor, y = price_difference)) +
  geom_boxplot(fill = "lightgrey", color = "darkgrey", alpha = 0.7) +
  labs(x = "Vendor", y = "Price Difference (in $)") +
  theme_minimal()

```

Figure 3 (@fig-price_difference_by_vendor) illustrates the distribution of price differences between beef products offered by two vendors, T&T and Walmart, providing an insight into the variability of pricing across these retailers. The y-axis represents the price difference in dollars, while the x-axis labels the two vendors under comparison. The boxplots visually depict the range, median, and variability in the price differences for each vendor.

For T&T, the boxplot shows a wider range of price differences, with the interquartile range (IQR) extending from roughly \$1.5 to \$4, indicating a moderate to substantial variability in price differences among the products they sell. The median price difference is around \$2.5, suggesting that many of the products have a price difference near this value. However, T&T also shows significant variability with the presence of two outliers beyond \$7.5 and \$10, indicating that a few beef products exhibit much larger price differences compared to the rest of the data.

In contrast, Walmart exhibits a narrower spread of price differences, as indicated by the more compact boxplot. The IQR for Walmart lies approximately between \$1 and \$2.5, and the median price difference is lower compared to T&T, close to \$1.5. This suggests that Walmart’s beef products tend to have smaller and less variable price differences, indicating more consistent pricing practices. There are also a few outliers above \$4, but these are less extreme compared to T&T's outliers.

Overall, the boxplots suggest that T&T has more variability in their pricing, possibly reflecting differences in product types or marketing strategies, whereas Walmart tends to maintain a narrower price range with fewer significant deviations. This disparity may indicate that Walmart focuses on more standardized pricing practices, which could influence consumer choice based on price predictability and consistency.

```{r}
#| label: fig-average_price_over_time
#| fig-cap: "Average Daily Current Price Over Time"
#| echo: false
#| warning: false
#| message: false

beef_data <- beef_data %>%
  mutate(date = as.Date(paste(year, month, day, sep = "-"), format = "%Y-%m-%d"))

avg_price_per_date <- beef_data %>%
  group_by(date) %>%
  summarise(avg_current_price = mean(current_price, na.rm = TRUE))

ggplot(avg_price_per_date, aes(x = date, y = avg_current_price)) +
  geom_point(color = "grey", size = 1.5, alpha = 0.7) +
  geom_smooth(method = "loess", color = "red", fill = "darkgrey", alpha = 0.3, se = TRUE) +
  labs(x = "Date", y = "Average Current Price (in $)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Figure 4 (@fig-average_price_over_time) shows the trend of average beef prices over time, providing insight into fluctuations in the market from July to November. The y-axis represents the average current price in \$, while the x-axis represents the date, with labels indicating the progression through the months.

The line chart indicates that average beef prices experienced significant variability throughout the observed period, with several sharp peaks and troughs. In early July, prices were relatively high, reaching a peak of approximately \$13, but this was followed by a rapid decline, dropping to around \$7 by the end of the month. The fluctuations continue through August, where we see notable volatility, including several spikes back to higher average prices of over \$10. Such fluctuations suggest sensitivity in pricing, possibly influenced by seasonal changes, supply chain disruptions, or market demand dynamics.

Entering September and October, there is a pronounced drop in prices, with average prices occasionally dipping below \$6, reflecting a period of reduced pricing. Following this low, prices exhibit recovery and some stabilization, hovering around \$8 to \$9 from October into early November, albeit with some ongoing small fluctuations. The chart’s volatility indicates that beef prices are influenced by various factors throughout these months, with possible implications from supply conditions, retailer pricing strategies, or changing consumer demand. This temporal analysis of beef pricing is critical for understanding market stability and identifying periods of significant price changes that may warrant further investigation.

```{r}
#| label: fig-current_vs_old_price
#| fig-cap: "Relationship Between Old and Current Beef Price Levels"
#| echo: false
#| warning: false
#| message: false

# Create price levels for old_price and current_price with finer granularity
beef_data <- beef_data %>%
  mutate(
    old_price_level = cut(old_price, breaks = seq(0, max(old_price, na.rm = TRUE), by = 2), include.lowest = TRUE),
    current_price_level = cut(current_price, breaks = seq(0, max(current_price, na.rm = TRUE), by = 2), include.lowest = TRUE)
  )

# Count occurrences of price levels
price_level_counts <- beef_data %>%
  count(old_price_level, current_price_level, name = "count")

# Create the heatmap
ggplot(data = price_level_counts, aes(x = old_price_level, y = current_price_level, fill = count)) +
  geom_tile(color = "lightgrey") +
  scale_fill_gradient(low = "lightgrey", high = "red", name = "Frequency") +
  labs( x = "Old Price Level", y = "Current Price Level") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```

Figure 5 (@fig-current_vs_old_price) has been modified to display a heatmap of the relationship between old and current price levels for beef, providing a more aggregated view of how pricing has evolved over time for various products. The x-axis represents the old price level, while the y-axis indicates the current price level, with each cell in the heatmap representing a specific combination of these price levels. The color intensity, ranging from light red to dark red, corresponds to the frequency of observations, as indicated by the legend on the right.

The heatmap reveals a clear diagonal pattern where higher old price levels correspond to higher current price levels, indicating a strong positive association between historical and current pricing. The darker cells along the diagonal reflect the highest frequency of observations, suggesting that most products maintain similar relative pricing over time, reinforcing the consistency in price adjustments observed earlier. This alignment along the diagonal suggests that beef pricing adjustments have been proportional and systematic, potentially influenced by inflation, consistent vendor practices, or other market mechanisms.

The off-diagonal cells that are lightly shaded or empty indicate fewer occurrences where current prices deviate significantly from historical ones. The absence of significant variation off the main diagonal suggests that the majority of pricing changes for beef are directly related to past prices, implying stability in pricing trends with limited irregular adjustments. This consistency may be indicative of structured pricing strategies across different market conditions, with only minor deviations that could result from specific product promotions or temporary supply issues.

Overall, the heatmap effectively illustrates the overall pattern of pricing consistency, highlighting that both old and current beef prices are closely aligned. This representation captures the density of occurrences more clearly than individual scatter points, providing a visual summary of the frequency and typicality of price pairings between historical and current beef prices.

```{r}
#| label: fig-unit_price_distribution
#| fig-cap: "Distribution of Unit Prices"
#| echo: false
#| warning: false
#| message: false

ggplot(beef_data, aes(x = price_per_unit)) +
  geom_density(fill = "lightgrey", color = "red", , linewidth = 0.8, alpha = 0.5, bw = 0.5) +
  labs(x = "Unit Price ($ per 100 grams)", y = "Density") +
  theme_minimal()

```

Figure 6 (@fig-unit_price_distribution) illustrates the distribution of unit prices for beef, measured in \$ per 100 grams. The x-axis represents the unit price, while the y-axis indicates the frequency of occurrences for each price range. The histogram, represented by grey bars, shows how often each unit price appears in the dataset, and the red curve provides a smoothed density estimate to visualize the general trend.

The most striking feature of this figure is the concentration of unit prices near zero, with a significant spike in the frequency at this price point. This suggests that a substantial number of observations in the dataset have a very low or nominal unit price, which could indicate promotions, discounted products, or even data entry inconsistencies that require further examination. After this initial peak, the frequency drops sharply, followed by a few smaller peaks across higher unit price ranges, particularly around \$1, \$3, and \$6 per 100 grams. These smaller peaks indicate the presence of additional groupings of unit prices, potentially corresponding to different product categories, quality grades, or pricing tiers.

The overall distribution is heavily right-skewed, suggesting that the majority of beef products have lower unit prices, while higher prices are less common and scattered. This right-skewness might be indicative of pricing strategies that cater to a wide consumer base, where most products are priced affordably, with only a few premium items available at significantly higher unit prices. The presence of several distinct peaks, rather than a single uniform distribution, suggests price differentiation that could be driven by various factors, such as beef cut type, quality, or retailer-specific pricing strategies. This distribution pattern highlights the diverse pricing landscape for beef products in the dataset, suggesting the existence of both low-cost and premium segments in the market.



## Modeling

```{r}
#| label: tbl-modelresults
#| tbl-cap: "Beef model results"
#| echo: false
#| warning: false
#| message: false

modelsummary::modelsummary(
  list(
    "Beef model (Bayesian)" = beef_model
  ),
  statistic = "mad",
  fmt = 2
)

```

Table 5 (@tbl-modelresults) summarizes the results from the Bayesian model applied to analyze beef prices, including key parameter estimates and model diagnostics. The model provides insight into the relationship between the current price of beef and various predictors such as the old price, vendor, and the time of observation (represented by the "month" variable).

The estimated intercept of -0.37 suggests that, after controlling for the predictors in the model, the baseline level of the current price is negative, though this value must be interpreted with caution in terms of its contextual implications. The "month" coefficient is -0.01, indicating a slight negative association between the time variable and current price, although the magnitude of the effect is relatively small. This suggests that as time progresses, there is a minor decrease in the current price, potentially reflecting seasonal effects or gradual changes in market dynamics. The "old_price" coefficient is 0.81, showing a strong positive relationship with the current price, meaning that for each unit increase in the old price, the current price increases by a comparable margin. This result implies a consistent upward adjustment in beef pricing over time, reinforcing the trends seen in previous charts. Finally, the "vendorWalmart" coefficient is 0.56, indicating that beef sold by Walmart tends to be priced higher, on average, than that sold by the baseline vendor (T&T), which aligns with our earlier findings on vendor price differences.

In terms of model fit, the R-squared (R²) value of 0.945 and the adjusted R-squared value of 0.944 indicate a high degree of explained variance, suggesting that the model is capable of capturing the main factors influencing beef prices. The negative log-likelihood value (-4349.672) and expected log pointwise predictive density (ELPD) of -4354.7 provide additional metrics on model fit, while other diagnostic values, such as the leave-one-out information criterion (LOOIC) and Widely Applicable Information Criterion (WAIC), both around 8709, provide an indication of model performance for out-of-sample predictive accuracy. The root mean square error (RMSE) is 1.02, suggesting the model's predictions have a relatively small average deviation from the actual values, indicative of good predictive performance.

These results together illustrate the strong relationship between past pricing and current pricing, as well as vendor influence on beef pricing. The Bayesian approach has provided robust parameter estimates while accounting for uncertainty, as reflected in the provided standard errors. Overall, the model appears to perform well, with high explained variance and reasonable prediction accuracy, making it a valuable tool for understanding and forecasting beef price trends.

# Discussion {#sec-discussion}

## Interpretation of Findings

The findings of this study provide valuable insights into the dynamics of beef pricing in the Canadian grocery market. Through the application of Bayesian linear regression, it is evident that both historical pricing (i.e., old_price) and vendor-specific strategies significantly influence the current pricing of beef. The strong positive correlation between old_price and current_price suggests a consistency in pricing practices, potentially driven by factors like inflation and vendor pricing strategies, with beef products generally following historical pricing trends. The vendor effect, notably the difference between T&T and Walmart, reflects distinct market positioning strategies, with Walmart generally maintaining a more standardized pricing approach, whereas T&T displays greater variability, possibly influenced by its focus on specialty goods catering to specific cultural preferences. Seasonal trends, captured through the month variable, also indicate minor temporal price variations, pointing to possible supply and demand effects linked to particular times of the year.

The heatmap visualizations, scatter plots, and statistical summaries all pointed towards a consistent trend in pricing, with limited deviations from expected relationships between historical and current prices. The consistency observed in the heatmap between old and current price levels suggests that vendors are either directly responding to historical costs or that other external factors, such as cost of production, inflation, or market demand, are similarly affecting historical and current pricing. The results of the Bayesian model further support these findings, highlighting the importance of including historical price as a predictor in understanding current pricing trends. The high R-squared value of the model also indicates that the chosen predictors adequately capture most of the variability in beef prices, reinforcing the relevance of the variables selected.

## Vendor-Specific Pricing Strategies

One critical point of discussion is the apparent distinction in pricing strategies between Walmart and T&T. Walmart's pricing, as evidenced by the relatively narrow spread of the boxplot, seems to prioritize consistency and predictability, possibly reflecting its brand strategy of offering everyday low prices [@citeWalmartLowPrice]. This approach may be designed to build consumer trust, ensuring customers that they are receiving competitive pricing without frequent fluctuations. On the other hand, T&T's wider range of price differences may reflect a more dynamic pricing strategy, potentially influenced by the specialty nature of its products [@citeTandT], diverse supply chain, or its responsiveness to a different customer demographic. Such variability in pricing could indicate promotional efforts, targeted price differentiation, or a reflection of its broader range of product quality and types.

This analysis highlights the importance of understanding different vendor strategies when interpreting pricing data. Walmart's emphasis on standardized pricing could attract a broader, price-sensitive customer base, while T&T's more variable pricing might appeal to niche customers seeking specific products, regardless of price changes. Future research could delve deeper into these strategies by including additional variables that capture product-specific characteristics, customer demographics, or promotion periods to better understand the pricing differences observed.

## Price Stability and Market Forces

The study also suggests that beef pricing is relatively stable, with most price adjustments being proportional to historical prices. This stability might imply a well-functioning market where historical prices act as an anchor, helping vendors and consumers set expectations. This could also be indicative of supply-side factors such as contracts with suppliers or production costs that do not fluctuate significantly. Additionally, the moderate decrease in prices observed during certain months might suggest seasonal promotions or shifts in consumer demand that lead vendors to adjust prices accordingly. Such trends could be driven by factors like increased competition, holiday promotions [@citeHoliday], or seasonal variations in meat consumption.

Interestingly, the observed concentration of prices in the lower range might indicate that the majority of beef products are targeted towards value-oriented consumers, potentially reflecting broader consumer preferences or economic constraints. This could also point to the influence of retailer pricing power, where large players like Walmart are able to leverage economies of scale to keep prices low, thereby shaping overall market dynamics. An important next step in understanding these patterns would be to assess how external shocks, such as economic downturns or supply chain disruptions [@citeSupplyChain], influence this pricing stability, as well as whether similar patterns hold for other product categories.

## Weaknesses and Future Directions

While the study offers useful insights into beef pricing dynamics, it is important to acknowledge several limitations. First, the dataset used was limited to two vendors, Walmart and T&T, which may not fully represent the diversity of the Canadian grocery market. Including more vendors could provide a broader perspective on pricing strategies across different types of retailers, such as discount chains, premium grocers, or independent stores [@citeBrand]. Additionally, the current analysis did not account for factors like promotions, product quality differences, or customer loyalty programs [@citeProgram], which could play significant roles in pricing decisions. Including such variables in future models could provide a more nuanced understanding of the factors influencing beef prices.

The model assumes a linear relationship between predictors and the outcome variable, which might oversimplify the complexity of real-world pricing behavior. Future work could explore more sophisticated modeling techniques, such as non-linear models or machine learning approaches, to capture potential non-linearities in the data. Additionally, the study relied on a single dataset, and incorporating external data sources—such as economic indicators, weather data, or detailed sales information—could help validate and enrich the findings.

Finally, the assumption of constant variance and normality of residuals may not hold perfectly in the context of pricing data, which can often exhibit heteroscedasticity or other forms of non-normality. Implementing more robust regression techniques or exploring heteroscedasticity-consistent estimators could help improve model reliability and accuracy. Another interesting avenue for future research would be to examine the impact of consumer behavior changes, such as shifts towards plant-based alternatives, on beef pricing trends, which could provide insights into evolving market dynamics.

\newpage

\appendix

# Appendix {-}

# Additional data details

## Vendor Choice
The selection of Walmart and T&T as representative vendors for this analysis was driven by their distinctive characteristics and market coverage, which together offer a comprehensive view of beef pricing dynamics. Walmart is a prominent multinational retailer with a broad presence across North America, making it a well-suited representative of mainstream, large-scale grocery retailing. Its extensive reach and emphasis on standardized pricing provide valuable insights into the general market trends and pricing behaviors that are accessible to a wide segment of consumers. By including Walmart in the analysis, we can capture a perspective that is reflective of the typical shopping experience for many consumers, characterized by competitive pricing and a broad product selection.

On the other hand, T&T Supermarket represents a niche segment of the market, catering specifically to Asian communities and consumers seeking specialty goods that align with Asian culinary traditions. T&T's focus on products tailored to Asian tastes, along with its unique supply chains and vendor relationships, provides an important contrast to Walmart. The inclusion of T&T allows for an exploration of how cultural preferences and niche market positioning influence pricing. By analyzing T&T, we gain insights into pricing practices that reflect the demands of a distinct consumer group and how these differ from the broader market.

The combination of Walmart and T&T enables the analysis to explore both mainstream and culturally specific market behaviors. This choice of vendors thus enriches the study by accounting for variations in consumer preferences, pricing strategies, and market positioning. Walmart's emphasis on scale and cost-efficiency contrasts with T&T's specialization and cultural targeting, allowing us to draw meaningful comparisons in terms of beef pricing strategies between a general and a specialized market context. Such a nuanced understanding is essential for capturing the diversity within the beef retail market, providing a more holistic view of the factors driving beef prices in different retail settings.

\newpage

## Price per unit

In cleaning the `price_per_unit` variable, I began by extracting the numerical value using `str_extract()`, which allowed me to identify the dollar amounts in the original string (`\\$[0-9\\.]+`), as shown in @tbl-price_per_unit-1. This step ensured that only valid price values, starting with a dollar sign, were captured, removing any extraneous text or symbols.

Next, I removed the dollar sign itself with `str_remove("\\$")` to convert the extracted value into a format suitable for numerical operations. After this, I used `as.numeric()` to convert the string into a numeric type, allowing for further quantitative analysis.

To handle missing values, I applied `ifelse(is.na(price_per_unit), 0, price_per_unit)`, which replaced any `NA` values in the `price_per_unit` column with `0`. This step ensured that all rows had a value for `price_per_unit`, preventing issues during subsequent analysis. Using zero as the replacement helped maintain continuity in the dataset, although I acknowledge that this choice could imply that missing values are negligible, which might require additional context or consideration during interpretation. The price_per_unit column in the dataset after cleaning looks like @tbl-price_per_unit-2.

```{r}
#| label: tbl-price_per_unit
#| tbl-cap: "Price per Unit Data for TandT and Walmart"
#| tbl-subcap: ["Raw Data", "Cleaned Data"]
#| echo: false
#| warning: false
#| message: false
#| layout-ncol: 2

ppu_data %>%
  filter(vendor == "TandT") %>%
  head(6) %>%
  bind_rows(
    ppu_data %>%
      filter(vendor == "Walmart") %>%
      head(6)
  ) %>%
  kable(
    col.names = c("Vendor", "Price per Unit"),
    booktabs = TRUE
  )

beef_data %>%
  filter(vendor %in% c("TandT", "Walmart")) %>%
  select(vendor, price_per_unit) %>%
  group_by(vendor) %>%
  summarise(price_per_unit = list(head(price_per_unit))) %>%
  tidyr::unnest(price_per_unit) %>%
  kable(
    col.names = c("Vendor", "Price per Unit"),
    booktabs = TRUE
  )

```

\newpage

# Model details {#sec-model-details}

## Posterior predictive check
In @fig-ppcheck, we implement a posterior predictive check. This plot shows the observed data distribution (in dark lines) compared with simulated datasets from the posterior (in light grey lines). The purpose of this check is to evaluate how well the model can reproduce the observed data. The close alignment between the simulated posterior predictive distributions and the observed data suggests that the model is accurately capturing the underlying patterns in the data. Specifically, we observe that the peaks and troughs in the observed data are well represented by the posterior samples, indicating that the model is capable of capturing key features such as the general shape and spread of the data distribution. The variability across the posterior predictive samples is consistent with the observed variability, suggesting no significant model misfit.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheck
#| fig-cap: "Posterior prediction check result"

# Posterior predictive check
pp_check(beef_model, plotfun = "dens_overlay")

```

\newpage

In @fig-posteriorvsprior, we compare the posterior with the prior distributions for each parameter. The posterior distribution (shown on the left) is more concentrated compared to the prior (shown on the right), which demonstrates how the data has influenced and updated our beliefs about the model parameters. For instance, the posterior distribution for the intercept has shrunk considerably compared to its prior, indicating that the data has substantially informed our estimate of the baseline price level. Similarly, for the other parameters (month, old_price, sigma, and vendorWalmart), the posteriors are less dispersed than the priors, suggesting a meaningful reduction in uncertainty. Notably, the posterior intervals are much narrower, especially for the intercept and old price parameters, indicating that the data has provided strong information about these effects. The results demonstrate that the priors were sufficiently weak, allowing the data to dominate the inference and significantly refine the parameter estimates.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-posteriorvsprior
#| fig-cap: "Comparing the posterior with the prior"

# Comparing posterior with prior
posterior_vs_prior(beef_model, color_by = "parameter") +
  theme_minimal() +
  scale_fill_grey() +
  scale_color_grey() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

\newpage

## Diagnostics
In @fig-trace, we present a trace plot. This plot shows the sampled values for each parameter across the MCMC iterations. The trace plot helps assess whether the chains have converged to a stationary distribution. In these plots, we see that each parameter's chains are well mixed, with no discernible trends, indicating that the MCMC algorithm has adequately explored the parameter space. The lack of significant upward or downward drift suggests that all chains are consistently sampling from the target distribution, which is a strong indicator of convergence.

Specifically, the chains for each parameter appear to oscillate around a constant mean, and the overlap between the four chains is extensive. This well-mixed appearance across all parameters, including the intercept, month, old price, vendorWalmart, and sigma, gives us confidence that our model has reached convergence, with each chain sampling from similar regions of the posterior distribution.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-trace
#| fig-cap: "Trace plot"

# Trace plot
plot(beef_model, plotfun = "trace") + theme_minimal()

```

\newpage

In @fig-rhat, we present an Rhat plot. The Rhat statistic (also known as the potential scale reduction factor) measures the ratio of the variance between chains to the variance within chains, and values close to 1 indicate that the chains have converged. In this plot, we see that all Rhat values for the parameters are very close to 1, specifically below the threshold of 1.05, suggesting that convergence has been achieved across all parameters.

The fact that all Rhat values are below 1.05 suggests that the different chains are in agreement about the underlying posterior distributions. This indicates that our model's parameter estimates are stable, and the MCMC algorithm has effectively converged. As such, we can be confident in the reliability of the estimates provided by our Bayesian model.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-rhat
#| fig-cap: "Rhat plot"

# Rhat plot
plot(beef_model, plotfun = "rhat") + theme_minimal()

```

\newpage

# Idealized Methodology for a Survey on Beef Pricing {#sec-survey}

## Overview

To complement the quantitative analysis presented in this paper, an idealized survey methodology could provide direct insights into consumer behavior and perceptions regarding beef pricing at Walmart and T&T. This survey would aim to identify factors influencing purchasing decisions, perceptions of price fairness, and preferences for vendor-specific attributes, offering a holistic understanding of the dynamics underpinning beef pricing in the Canadian grocery market.

## Sampling Approach

A **stratified random sampling** method would be employed to ensure representation across key demographic groups, including age, income levels, and cultural background. Stratification variables would include:

1. **Region**: Urban versus rural shoppers across Canada.
2. **Vendor familiarity**: Regular Walmart shoppers, regular T&T shoppers, and those who shop at both.
3. **Income brackets**: Low, middle, and high-income households.

A sample size of approximately 1,200 respondents would be targeted, with 400 participants in each stratum (Walmart-focused, T&T-focused, and dual shoppers). This stratification would allow for meaningful comparisons between vendor-specific perceptions and strategies.

## Survey Structure

The survey would include a mix of **closed-ended** and **open-ended** questions.

### Question Types

1. **Demographics and Shopping Habits**
   - Frequency of grocery shopping (weekly, bi-weekly, etc.).
   - Preferred vendor for beef purchases and reasons for preference.
   - Average budget allocated for beef purchases.

2. **Price Perception**
   - Rating the perceived fairness of beef prices on a Likert scale.
   - Comparison of beef prices at Walmart and T&T (e.g., cheaper, equivalent, more expensive).
   - Sensitivity to price changes (e.g., a 10% increase in beef prices would lead to…).

3. **Cultural and Quality Preferences**
   - Importance of cultural alignment in beef products (specific cuts, preparation styles, etc.).
   - Perceived quality differences between Walmart and T&T beef products.
   - Willingness to pay a premium for culturally tailored products.

4. **External Factors**
   - Awareness of seasonal price trends.
   - Impact of promotions on purchasing decisions.
   - Responses to supply chain disruptions (e.g., alternative purchasing strategies).

### Question List

1. How often do you shop for groceries?
   - Weekly
   - Bi-weekly
   - Monthly
   - Less often

2. Which retailer do you prefer for buying beef products?
   - Walmart
   - T&T
   - Both

3. What factors influence your choice of retailer for beef purchases? (Select all that apply)
   - Price
   - Quality
   - Availability of specific cuts
   - Cultural preferences
   - Convenience
   - Promotions

4. On average, how much do you spend on beef per shopping trip?
   - Less than $20
   - \$20 - \$50
   - \$50 - \$100
   - More than $100

5. How fair do you find the current beef prices at Walmart/T&T?
   - Very unfair
   - Somewhat unfair
   - Neutral
   - Somewhat fair
   - Very fair

6. How would you rate the quality of beef at Walmart compared to T&T?
   - Much lower quality
   - Slightly lower quality
   - About the same quality
   - Slightly higher quality
   - Much higher quality

7. If beef prices increased by 10%, would you consider switching to an alternative product or retailer?
   - Definitely would switch
   - Probably would switch
   - Might switch
   - Probably would not switch
   - Definitely would not switch

8. How important is it for you that beef products align with your cultural preferences (e.g., specific cuts, preparation styles)?
   - Not important at all
   - Slightly important
   - Moderately important
   - Very important
   - Extremely important

9. Are you willing to pay more for beef products that are culturally tailored to your preferences?
   - Not willing at all
   - Slightly willing
   - Moderately willing
   - Very willing
   - Extremely willing

10. How aware are you of seasonal price changes in beef products?
    - Not aware at all
    - Slightly aware
    - Moderately aware
    - Very aware
    - Extremely aware

11. How do promotions impact your decision to purchase beef?
    - No impact
    - Slight impact
    - Moderate impact
    - Significant impact
    - Very significant impact

12. How do you typically respond to supply chain disruptions affecting beef availability?
    - Purchase alternative products
    - Purchase from a different retailer
    - Reduce beef consumption
    - No change in purchasing behavior

## Recruitment Strategy

Participants would be recruited using **multichannel outreach**, including:

1. **Online Panels**: Partnering with Canadian consumer research platforms to recruit participants from diverse regions.
2. **Retailer Partnerships**: Collaborating with Walmart and T&T to survey in-store shoppers (e.g., QR codes on receipts leading to the survey).
3. **Community Outreach**: Engaging with cultural organizations to reach underrepresented groups, particularly for T&T shoppers.

## Linkage to Literature





\newpage


# References


